"""
æ‰¹é‡å¤„ç†è·¯ç”± - æ”¯æŒæ‰¹é‡LLMè§£æå’Œæ‰¹é‡TTSé…éŸ³
æ‰€æœ‰æ“ä½œé€šè¿‡ WebSocket æ¨é€å®æ—¶æ—¥å¿—å’Œè¿›åº¦
"""

import asyncio
import json
import logging
import os
import random
import traceback
from typing import List, Optional

from fastapi import APIRouter, Depends, HTTPException
from pydantic import BaseModel
from sqlalchemy.orm import Session

from py.core.config import get_data_dir
from py.core.response import Res
from py.core.text_correct_engine import TextCorrectorFinal
from py.core.ws_manager import manager
from py.db.database import get_db, SessionLocal
from py.dto.line_dto import LineInitDTO
from py.repositories.chapter_repository import ChapterRepository
from py.repositories.emotion_repository import EmotionRepository
from py.repositories.line_repository import LineRepository
from py.repositories.llm_provider_repository import LLMProviderRepository
from py.repositories.project_repository import ProjectRepository
from py.repositories.prompt_repository import PromptRepository
from py.repositories.role_repository import RoleRepository
from py.repositories.strength_repository import StrengthRepository
from py.repositories.tts_provider_repository import TTSProviderRepository
from py.repositories.voice_repository import VoiceRepository
from py.services.chapter_service import ChapterService
from py.services.emotion_service import EmotionService
from py.services.line_service import LineService
from py.services.project_service import ProjectService
from py.services.prompt_service import PromptService
from py.services.role_service import RoleService
from py.services.strength_service import StrengthService
from py.services.voice_service import VoiceService
from py.services.multi_emotion_voice_service import MultiEmotionVoiceService
from py.repositories.multi_emotion_voice_repository import MultiEmotionVoiceRepository
from py.core.tts_runtime import emotion_text_to_vector

logger = logging.getLogger("hx-saybook.batch")

router = APIRouter(prefix="/batch", tags=["Batch"])


# ============================================================
# è¯·æ±‚ DTO
# ============================================================


class BatchLLMRequest(BaseModel):
    """æ‰¹é‡ LLM è§£æè¯·æ±‚"""

    project_id: int
    chapter_ids: List[int]  # æ”¯æŒé€‰æ‹©ç« èŠ‚èŒƒå›´
    concurrency: int = 1  # å¹¶å‘æ•°ï¼Œé»˜è®¤1ï¼ŒèŒƒå›´1~10
    skip_parsed: bool = True  # è·³è¿‡å·²è§£æè¿‡çš„ç« èŠ‚ï¼ˆé»˜è®¤å¼€å¯ï¼‰


class BatchTTSRequest(BaseModel):
    """æ‰¹é‡ TTS é…éŸ³è¯·æ±‚"""

    project_id: int
    chapter_ids: List[int]
    speed: float = 1.0  # å…¨å±€é€Ÿåº¦è°ƒèŠ‚


class VoicePreviewRequest(BaseModel):
    """è¯­éŸ³é¢„è§ˆè¯·æ±‚"""

    text: str
    voice_id: int
    tts_provider_id: int
    emotion_name: str = "å¹³é™"
    strength_name: str = "ä¸­ç­‰"
    speed: float = 1.0
    language: Optional[str] = None  # è¯­è¨€: "zh"(ä¸­æ–‡) / "ja"(æ—¥è¯­)


class VoiceDebugRequest(BaseModel):
    """è¯­éŸ³è°ƒè¯•è¯·æ±‚"""

    text: str
    voice_id: int
    tts_provider_id: int
    emotion_name: str = "å¹³é™"
    strength_name: str = "ä¸­ç­‰"
    speed: float = 1.0
    language: Optional[str] = None  # è¯­è¨€: "zh"(ä¸­æ–‡) / "ja"(æ—¥è¯­)


# ============================================================
# è¾…åŠ©ä¾èµ–æ³¨å…¥
# ============================================================


def _get_services(db: Session):
    """ä¸€æ¬¡æ€§è·å–æ‰€æœ‰æ‰€éœ€ service"""
    return {
        "chapter": ChapterService(ChapterRepository(db)),
        "line": LineService(
            LineRepository(db), RoleRepository(db), TTSProviderRepository(db)
        ),
        "role": RoleService(RoleRepository(db)),
        "emotion": EmotionService(EmotionRepository(db)),
        "strength": StrengthService(StrengthRepository(db)),
        "prompt": PromptService(PromptRepository(db)),
        "project": ProjectService(ProjectRepository(db)),
        "voice": VoiceService(VoiceRepository(db), MultiEmotionVoiceRepository(db)),
        "multi_emotion": MultiEmotionVoiceService(MultiEmotionVoiceRepository(db)),
    }


# ============================================================
# æ‰¹é‡ LLM ä»»åŠ¡ç®¡ç†ï¼ˆæ”¯æŒå¹¶å‘ + å–æ¶ˆï¼‰
# ============================================================

# å­˜å‚¨è¿è¡Œä¸­çš„æ‰¹é‡LLMä»»åŠ¡: project_id -> {"cancel_event": asyncio.Event, "task": asyncio.Task}
_batch_llm_tasks: dict = {}


@router.post(
    "/llm-parse",
    response_model=Res,
    summary="æ‰¹é‡LLMè§£æç« èŠ‚",
    description="é€‰æ‹©ç« èŠ‚èŒƒå›´ï¼Œæ‰¹é‡è¿›è¡ŒLLMå°è¯æ‹†åˆ†ï¼Œæ”¯æŒå¹¶å‘å’Œå–æ¶ˆï¼Œé€šè¿‡WebSocketæ¨é€æ—¥å¿—å’Œè¿›åº¦",
)
async def batch_llm_parse(req: BatchLLMRequest):
    """æ‰¹é‡è§£æå¤šä¸ªç« èŠ‚ï¼Œé€šè¿‡ WS æ¨é€å®æ—¶è¿›åº¦"""
    # å¦‚æœè¯¥é¡¹ç›®å·²æœ‰è¿è¡Œä¸­çš„ä»»åŠ¡ï¼Œæ‹’ç»é‡å¤å¯åŠ¨
    if req.project_id in _batch_llm_tasks:
        return Res(code=400, message="è¯¥é¡¹ç›®å·²æœ‰æ‰¹é‡LLMä»»åŠ¡åœ¨è¿è¡Œä¸­ï¼Œè¯·å…ˆå–æ¶ˆåå†é‡è¯•")

    concurrency = max(1, min(10, req.concurrency))  # é™åˆ¶å¹¶å‘èŒƒå›´ 1~10
    cancel_event = asyncio.Event()
    task = asyncio.create_task(
        _do_batch_llm(
            req.project_id, req.chapter_ids, concurrency, cancel_event, req.skip_parsed
        )
    )
    _batch_llm_tasks[req.project_id] = {"cancel_event": cancel_event, "task": task}

    # ä»»åŠ¡ç»“æŸåè‡ªåŠ¨æ¸…ç†
    def _cleanup(fut):
        _batch_llm_tasks.pop(req.project_id, None)

    task.add_done_callback(_cleanup)

    return Res(
        code=200,
        message="æ‰¹é‡LLMè§£æä»»åŠ¡å·²å¯åŠ¨",
        data={"chapter_count": len(req.chapter_ids), "concurrency": concurrency},
    )


@router.get(
    "/llm-status",
    response_model=Res,
    summary="æŸ¥è¯¢æ‰¹é‡LLMä»»åŠ¡çŠ¶æ€",
    description="æŸ¥è¯¢æŒ‡å®šé¡¹ç›®æ˜¯å¦æœ‰æ­£åœ¨è¿è¡Œçš„æ‰¹é‡LLMä»»åŠ¡",
)
async def batch_llm_status(project_id: int):
    """æŸ¥è¯¢æ‰¹é‡LLMä»»åŠ¡æ˜¯å¦æ­£åœ¨è¿è¡Œ"""
    task_info = _batch_llm_tasks.get(project_id)
    if not task_info:
        return Res(code=200, message="æ— è¿è¡Œä¸­çš„ä»»åŠ¡", data={"running": False})

    return Res(
        code=200,
        message="ä»»åŠ¡è¿è¡Œä¸­",
        data={
            "running": True,
            "cancelled": task_info["cancel_event"].is_set(),
        },
    )


@router.post(
    "/llm-cancel",
    response_model=Res,
    summary="å–æ¶ˆæ‰¹é‡LLMè§£æ",
    description="å–æ¶ˆæ­£åœ¨è¿è¡Œçš„æ‰¹é‡LLMè§£æä»»åŠ¡",
)
async def batch_llm_cancel(project_id: int):
    """å–æ¶ˆæ­£åœ¨è¿è¡Œçš„æ‰¹é‡LLMä»»åŠ¡"""
    task_info = _batch_llm_tasks.get(project_id)
    if not task_info:
        return Res(code=404, message="æ²¡æœ‰æ­£åœ¨è¿è¡Œçš„æ‰¹é‡LLMä»»åŠ¡")

    task_info["cancel_event"].set()
    logger.info(f"æ‰¹é‡LLMä»»åŠ¡å–æ¶ˆä¿¡å·å·²å‘é€: project_id={project_id}")
    return Res(code=200, message="å–æ¶ˆä¿¡å·å·²å‘é€ï¼Œä»»åŠ¡å°†åœ¨å½“å‰ç« èŠ‚å¤„ç†å®Œæˆååœæ­¢")


async def _process_single_chapter_async(
    project_id: int,
    chapter_id: int,
    idx: int,
    total: int,
    cancel_event: asyncio.Event,
    done_counter: dict,
    skip_parsed: bool = False,
):
    """
    çº¯å¼‚æ­¥å¤„ç†å•ä¸ªç« èŠ‚çš„LLMè§£æ â€”â€” ç›´æ¥åœ¨äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œï¼Œä¸é˜»å¡ã€‚
    LLM è°ƒç”¨ä½¿ç”¨ AsyncOpenAIï¼Œæ‰€æœ‰ç½‘ç»œ IO å‡ä¸ºéé˜»å¡ã€‚
    å½“ skip_parsed=True æ—¶ï¼Œè‹¥ç« èŠ‚å·²æœ‰å°è¯æ•°æ®åˆ™è‡ªåŠ¨è·³è¿‡ã€‚
    """

    async def _broadcast(msg: dict):
        await manager.broadcast(msg)

    # æ£€æŸ¥æ˜¯å¦å·²å–æ¶ˆ
    if cancel_event.is_set():
        await _broadcast(
            {
                "event": "batch_llm_progress",
                "project_id": project_id,
                "chapter_id": chapter_id,
                "current": done_counter["done"],
                "total": total,
                "progress": round((done_counter["done"] / total) * 100),
                "status": "cancelled",
                "log": f"â¹ï¸ ç« èŠ‚ {chapter_id} å·²å–æ¶ˆ",
            }
        )
        return

    db = SessionLocal()
    try:
        services = _get_services(db)
        chapter_svc = services["chapter"]
        line_svc = services["line"]
        role_svc = services["role"]
        emotion_svc = services["emotion"]
        strength_svc = services["strength"]
        prompt_svc = services["prompt"]
        project_svc = services["project"]

        progress = round((done_counter["done"] / total) * 100)

        await _broadcast(
            {
                "event": "batch_llm_progress",
                "project_id": project_id,
                "chapter_id": chapter_id,
                "current": done_counter["done"] + 1,
                "total": total,
                "progress": progress,
                "status": "processing",
                "log": f"ğŸ“– å¼€å§‹è§£æç« èŠ‚ {chapter_id} ({done_counter['done'] + 1}/{total})",
            }
        )

        chapter = chapter_svc.get_chapter(chapter_id)
        if not chapter or not chapter.text_content:
            done_counter["done"] += 1
            await _broadcast(
                {
                    "event": "batch_llm_progress",
                    "project_id": project_id,
                    "chapter_id": chapter_id,
                    "current": done_counter["done"],
                    "total": total,
                    "progress": round((done_counter["done"] / total) * 100),
                    "status": "skipped",
                    "log": f"âš ï¸ ç« èŠ‚ {chapter_id} å†…å®¹ä¸ºç©ºï¼Œå·²è·³è¿‡",
                }
            )
            return

        # è·³è¿‡å·²è§£æè¿‡çš„ç« èŠ‚ï¼ˆæœ‰å°è¯æ•°æ® = å·²å®Œæˆå…¨éƒ¨æ®µè½çš„LLMè§£æå¹¶å†™å…¥ï¼‰
        if skip_parsed:
            existing_lines = line_svc.get_all_lines(chapter_id)
            if len(existing_lines) > 0:
                done_counter["done"] += 1
                await _broadcast(
                    {
                        "event": "batch_llm_progress",
                        "project_id": project_id,
                        "chapter_id": chapter_id,
                        "current": done_counter["done"],
                        "total": total,
                        "progress": round((done_counter["done"] / total) * 100),
                        "status": "skipped",
                        "log": f"â­ï¸ ç« èŠ‚ {chapter_id} å·²æœ‰ {len(existing_lines)} æ¡å°è¯ï¼Œè·³è¿‡é‡å¤è§£æ",
                    }
                )
                return

        # æ‹†åˆ†æ–‡æœ¬
        try:
            contents = chapter_svc.split_text(chapter_id, 1500)
            await _broadcast(
                {
                    "event": "batch_llm_log",
                    "project_id": project_id,
                    "chapter_id": chapter_id,
                    "log": f"ğŸ“ ç« èŠ‚æ–‡æœ¬åˆ’åˆ†ä¸º {len(contents)} æ®µ",
                }
            )
        except Exception as e:
            done_counter["done"] += 1
            await _broadcast(
                {
                    "event": "batch_llm_progress",
                    "project_id": project_id,
                    "chapter_id": chapter_id,
                    "current": done_counter["done"],
                    "total": total,
                    "progress": round((done_counter["done"] / total) * 100),
                    "status": "error",
                    "log": f"âŒ ç« èŠ‚æ‹†åˆ†å¤±è´¥: {e}",
                }
            )
            return

        # è·å–è§’è‰²ã€æƒ…ç»ªã€å¼ºåº¦
        roles = role_svc.get_all_roles(project_id)
        roles_set = set(role.name for role in roles)
        emotions = emotion_svc.get_all_emotions()
        strengths = strength_svc.get_all_strengths()
        emotion_names = [e.name for e in emotions]
        strength_names = [s.name for s in strengths]
        emotions_dict = {e.name: e.id for e in emotions}
        strengths_dict = {s.name: s.id for s in strengths}

        project = project_svc.get_project(project_id)
        is_precise_fill = project.is_precise_fill

        if not all(
            [project.tts_provider_id, project.llm_provider_id, project.llm_model]
        ):
            done_counter["done"] += 1
            await _broadcast(
                {
                    "event": "batch_llm_progress",
                    "project_id": project_id,
                    "chapter_id": chapter_id,
                    "current": done_counter["done"],
                    "total": total,
                    "progress": round((done_counter["done"] / total) * 100),
                    "status": "error",
                    "log": "âŒ é¡¹ç›®ç¼ºå°‘ TTS/LLM/Model é…ç½®",
                }
            )
            return

        prompt = prompt_svc.get_prompt(project.prompt_id) if project.prompt_id else None
        if not prompt:
            done_counter["done"] += 1
            await _broadcast(
                {
                    "event": "batch_llm_progress",
                    "project_id": project_id,
                    "chapter_id": chapter_id,
                    "current": done_counter["done"],
                    "total": total,
                    "progress": round((done_counter["done"] / total) * 100),
                    "status": "error",
                    "log": "âŒ æç¤ºè¯ä¸å­˜åœ¨",
                }
            )
            return

        # é€æ®µè§£æï¼ˆå¼‚æ­¥éé˜»å¡ï¼‰ï¼Œå¸¦æš‚åœé‡è¯•é€»è¾‘
        all_line_data = []
        parse_success = True
        MAX_SEG_RETRIES = 3  # æ¯æ®µæœ€å¤šé‡è¯•æ¬¡æ•°

        from py.core.llm_engine import _is_rate_limit_error

        for seg_idx, content in enumerate(contents):
            # æ¯æ®µè§£æå‰æ£€æŸ¥å–æ¶ˆä¿¡å·
            if cancel_event.is_set():
                done_counter["done"] += 1
                await _broadcast(
                    {
                        "event": "batch_llm_progress",
                        "project_id": project_id,
                        "chapter_id": chapter_id,
                        "current": done_counter["done"],
                        "total": total,
                        "progress": round((done_counter["done"] / total) * 100),
                        "status": "cancelled",
                        "log": f"â¹ï¸ ç« èŠ‚ {chapter_id} è§£æè¢«å–æ¶ˆ",
                    }
                )
                return

            seg_success = False
            for retry_idx in range(MAX_SEG_RETRIES):
                # é‡è¯•å‰ä¹Ÿæ£€æŸ¥å–æ¶ˆä¿¡å·
                if cancel_event.is_set():
                    done_counter["done"] += 1
                    return

                retry_hint = f"ï¼ˆç¬¬ {retry_idx + 1} æ¬¡é‡è¯•ï¼‰" if retry_idx > 0 else ""
                await _broadcast(
                    {
                        "event": "batch_llm_log",
                        "project_id": project_id,
                        "chapter_id": chapter_id,
                        "log": f"ğŸ”„ è§£æç¬¬ {seg_idx + 1}/{len(contents)} æ®µ...{retry_hint}",
                    }
                )

                try:
                    # ä½¿ç”¨å¼‚æ­¥éé˜»å¡ LLM è°ƒç”¨
                    result = await chapter_svc.para_content_async(
                        prompt.content,
                        chapter_id,
                        content,
                        list(roles_set),
                        emotion_names,
                        strength_names,
                        is_precise_fill,
                    )

                    if not result["success"]:
                        error_msg = result.get("message", "æœªçŸ¥é”™è¯¯")
                        # åˆ¤æ–­æ˜¯å¦ä¸ºè¯·æ±‚é¢‘ç¹ç±»é”™è¯¯ï¼Œå¦‚æœæ˜¯åˆ™æš‚åœåé‡è¯•
                        if (
                            _is_rate_limit_error(Exception(error_msg))
                            and retry_idx < MAX_SEG_RETRIES - 1
                        ):
                            wait_time = min(
                                15 * (2**retry_idx), 120
                            ) + random.uniform(1, 5)
                            await _broadcast(
                                {
                                    "event": "batch_llm_log",
                                    "project_id": project_id,
                                    "chapter_id": chapter_id,
                                    "log": f"â³ æ®µ {seg_idx + 1} è¯·æ±‚é¢‘ç¹: {error_msg}ï¼Œç­‰å¾… {wait_time:.0f}s åé‡è¯•...",
                                }
                            )
                            await asyncio.sleep(wait_time)
                            continue  # é‡è¯•å½“å‰æ®µ
                        else:
                            await _broadcast(
                                {
                                    "event": "batch_llm_log",
                                    "project_id": project_id,
                                    "chapter_id": chapter_id,
                                    "log": f"âŒ æ®µ {seg_idx + 1} è§£æå¤±è´¥: {error_msg}",
                                }
                            )
                            parse_success = False
                            break  # è·³å‡ºé‡è¯•å¾ªç¯

                    else:
                        lines_data = result["data"]
                        for ld in lines_data:
                            roles_set.add(ld.role_name)
                        all_line_data.extend(lines_data)

                        await _broadcast(
                            {
                                "event": "batch_llm_log",
                                "project_id": project_id,
                                "chapter_id": chapter_id,
                                "log": f"âœ… æ®µ {seg_idx + 1} è§£æå®Œæˆï¼Œè·å¾— {len(lines_data)} æ¡å°è¯",
                            }
                        )
                        seg_success = True
                        break  # è§£ææˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯

                except Exception as e:
                    logger.error(f"è§£æå¤±è´¥: {e}\n{traceback.format_exc()}")
                    # åˆ¤æ–­æ˜¯å¦ä¸ºè¯·æ±‚é¢‘ç¹ç±»é”™è¯¯
                    if _is_rate_limit_error(e) and retry_idx < MAX_SEG_RETRIES - 1:
                        wait_time = min(15 * (2**retry_idx), 120) + random.uniform(1, 5)
                        await _broadcast(
                            {
                                "event": "batch_llm_log",
                                "project_id": project_id,
                                "chapter_id": chapter_id,
                                "log": f"â³ æ®µ {seg_idx + 1} è¯·æ±‚é¢‘ç¹: {e}ï¼Œç­‰å¾… {wait_time:.0f}s åé‡è¯•...",
                            }
                        )
                        await asyncio.sleep(wait_time)
                        continue  # é‡è¯•å½“å‰æ®µ
                    else:
                        await _broadcast(
                            {
                                "event": "batch_llm_log",
                                "project_id": project_id,
                                "chapter_id": chapter_id,
                                "log": f"âŒ æ®µ {seg_idx + 1} è§£æå¼‚å¸¸: {e}",
                            }
                        )
                        parse_success = False
                        break  # è·³å‡ºé‡è¯•å¾ªç¯

            # å¦‚æœå½“å‰æ®µæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†ï¼Œç»ˆæ­¢åç»­æ®µçš„è§£æ
            if not seg_success and not parse_success:
                break

        if parse_success and all_line_data:
            # å†™å…¥æ•°æ®åº“
            try:
                # å…ˆæ¸…é™¤è¯¥ç« èŠ‚çš„æ—§å°è¯ï¼ˆé¿å…é‡æ–°è§£ææ—¶å°è¯é‡å¤å åŠ ï¼‰
                existing_lines = line_svc.get_all_lines(chapter_id)
                if len(existing_lines) > 0:
                    line_svc.delete_all_lines(chapter_id)
                    await _broadcast(
                        {
                            "event": "batch_llm_log",
                            "project_id": project_id,
                            "chapter_id": chapter_id,
                            "log": f"ğŸ—‘ï¸ å·²æ¸…é™¤ç« èŠ‚ {chapter_id} çš„ {len(existing_lines)} æ¡æ—§å°è¯",
                        }
                    )

                audio_path = os.path.join(
                    project.project_root_path,
                    str(project_id),
                    str(chapter_id),
                    "audio",
                )
                os.makedirs(audio_path, exist_ok=True)
                line_svc.update_init_lines(
                    all_line_data,
                    project_id,
                    chapter_id,
                    emotions_dict,
                    strengths_dict,
                    audio_path,
                )

                done_counter["done"] += 1
                await _broadcast(
                    {
                        "event": "batch_llm_progress",
                        "project_id": project_id,
                        "chapter_id": chapter_id,
                        "current": done_counter["done"],
                        "total": total,
                        "progress": round((done_counter["done"] / total) * 100),
                        "status": "done",
                        "log": f"âœ… ç« èŠ‚ {chapter_id} è§£æå®Œæˆï¼Œå…± {len(all_line_data)} æ¡å°è¯",
                    }
                )
            except Exception as e:
                done_counter["done"] += 1
                await _broadcast(
                    {
                        "event": "batch_llm_progress",
                        "project_id": project_id,
                        "chapter_id": chapter_id,
                        "current": done_counter["done"],
                        "total": total,
                        "progress": round((done_counter["done"] / total) * 100),
                        "status": "error",
                        "log": f"âŒ å†™å…¥æ•°æ®åº“å¤±è´¥: {e}",
                    }
                )
        else:
            done_counter["done"] += 1
            await _broadcast(
                {
                    "event": "batch_llm_progress",
                    "project_id": project_id,
                    "chapter_id": chapter_id,
                    "current": done_counter["done"],
                    "total": total,
                    "progress": round((done_counter["done"] / total) * 100),
                    "status": "error",
                    "log": f"âŒ ç« èŠ‚ {chapter_id} è§£æå¤±è´¥",
                }
            )

    except Exception as e:
        logger.error(f"æ‰¹é‡LLMå¤„ç†å¼‚å¸¸: {e}\n{traceback.format_exc()}")
        done_counter["done"] += 1
        await _broadcast(
            {
                "event": "batch_llm_progress",
                "project_id": project_id,
                "chapter_id": chapter_id,
                "current": done_counter["done"],
                "total": total,
                "progress": 0,
                "status": "error",
                "log": f"âŒ æœªçŸ¥é”™è¯¯: {e}",
            }
        )
    finally:
        db.close()


async def _do_batch_llm(
    project_id: int,
    chapter_ids: List[int],
    concurrency: int,
    cancel_event: asyncio.Event,
    skip_parsed: bool = True,
):
    """åå°æ‰§è¡Œæ‰¹é‡LLMè§£æï¼ˆæ”¯æŒå¹¶å‘ + å–æ¶ˆï¼Œçº¯åç¨‹æ— çº¿ç¨‹æ± ï¼‰"""
    total = len(chapter_ids)
    semaphore = asyncio.Semaphore(concurrency)
    # ä½¿ç”¨ dict åšè®¡æ•°å™¨ä»¥ä¾¿åœ¨åç¨‹é—´å…±äº«
    done_counter = {"done": 0}

    async def _sem_wrapper(chapter_id: int, idx: int):
        # åœ¨ç­‰å¾…ä¿¡å·é‡ä¹‹å‰å°±æ£€æŸ¥å–æ¶ˆï¼Œé¿å…æ’é˜Ÿçš„ä»»åŠ¡é€ä¸ªèµ°å–æ¶ˆæµç¨‹
        if cancel_event.is_set():
            return
        async with semaphore:
            if cancel_event.is_set():
                return
            await _process_single_chapter_async(
                project_id,
                chapter_id,
                idx,
                total,
                cancel_event,
                done_counter,
                skip_parsed,
            )
            # é¿å…è¿‡å¿«è¯·æ±‚LLM
            await asyncio.sleep(0.3)

    # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
    tasks = [
        asyncio.create_task(_sem_wrapper(cid, idx))
        for idx, cid in enumerate(chapter_ids)
    ]

    # ç­‰å¾…å®Œæˆæˆ–å–æ¶ˆ
    # å¯åŠ¨ä¸€ä¸ªç›‘æ§åç¨‹ï¼Œå–æ¶ˆä¿¡å·åˆ°è¾¾æ—¶ç«‹å³ cancel æ‰€æœ‰æœªå®Œæˆçš„ä»»åŠ¡
    async def _cancel_watcher():
        # asyncio.Event.wait æ˜¯éé˜»å¡åç¨‹ï¼Œæ— éœ€çº¿ç¨‹æ± 
        await cancel_event.wait()
        for t in tasks:
            if not t.done():
                t.cancel()

    watcher = asyncio.create_task(_cancel_watcher())
    await asyncio.gather(*tasks, return_exceptions=True)
    watcher.cancel()

    # å‘é€å®Œæˆ/å–æ¶ˆäº‹ä»¶
    if cancel_event.is_set():
        await manager.broadcast(
            {
                "event": "batch_llm_complete",
                "project_id": project_id,
                "total": total,
                "cancelled": True,
                "log": f"â¹ï¸ æ‰¹é‡LLMè§£æå·²å–æ¶ˆï¼å·²å®Œæˆ {done_counter['done']}/{total} ä¸ªç« èŠ‚",
            }
        )
    else:
        await manager.broadcast(
            {
                "event": "batch_llm_complete",
                "project_id": project_id,
                "total": total,
                "cancelled": False,
                "log": f"ğŸ‰ æ‰¹é‡LLMè§£æå…¨éƒ¨å®Œæˆï¼å…±å¤„ç† {total} ä¸ªç« èŠ‚",
            }
        )


# ============================================================
# æ‰¹é‡ TTS é…éŸ³ï¼ˆæŒ‰ç« èŠ‚ä¸€é”®é…éŸ³ï¼‰
# ============================================================


@router.post(
    "/tts-generate",
    response_model=Res,
    summary="æ‰¹é‡TTSé…éŸ³",
    description="é€‰æ‹©ç« èŠ‚èŒƒå›´ï¼Œæ‰¹é‡è¿›è¡ŒTTSé…éŸ³ï¼Œé€šè¿‡WebSocketæ¨é€æ—¥å¿—å’Œè¿›åº¦",
)
async def batch_tts_generate(req: BatchTTSRequest):
    """æ‰¹é‡é…éŸ³å¤šä¸ªç« èŠ‚ï¼Œé€šè¿‡ WS æ¨é€å®æ—¶è¿›åº¦"""
    from starlette.requests import Request

    # è·å– app å®ä¾‹ä»¥è®¿é—® tts_queue
    # è¿™é‡Œç›´æ¥å¯åŠ¨å¼‚æ­¥ä»»åŠ¡
    task = asyncio.create_task(
        _do_batch_tts(req.project_id, req.chapter_ids, req.speed)
    )
    return Res(
        code=200,
        message="æ‰¹é‡TTSé…éŸ³ä»»åŠ¡å·²å¯åŠ¨",
        data={"chapter_count": len(req.chapter_ids)},
    )


async def _do_batch_tts(project_id: int, chapter_ids: List[int], speed: float = 1.0):
    """åå°æ‰§è¡Œæ‰¹é‡TTSé…éŸ³"""
    total_chapters = len(chapter_ids)
    total_lines = 0
    done_lines = 0

    # å…ˆç»Ÿè®¡æ€»å°è¯æ•°
    db = SessionLocal()
    try:
        services = _get_services(db)
        for cid in chapter_ids:
            lines = services["line"].get_all_lines(cid)
            total_lines += len([l for l in lines if l.role_id is not None])
    finally:
        db.close()

    await manager.broadcast(
        {
            "event": "batch_tts_start",
            "project_id": project_id,
            "total_chapters": total_chapters,
            "total_lines": total_lines,
            "log": f"ğŸ™ï¸ å¼€å§‹æ‰¹é‡é…éŸ³ï¼šå…± {total_chapters} ç« , {total_lines} æ¡å°è¯",
        }
    )

    for ch_idx, chapter_id in enumerate(chapter_ids):
        db = SessionLocal()
        try:
            services = _get_services(db)
            line_svc = services["line"]
            role_svc = services["role"]
            voice_svc = services["voice"]
            emotion_svc = services["emotion"]
            strength_svc = services["strength"]
            project_svc = services["project"]
            multi_emotion_svc = services["multi_emotion"]

            project = project_svc.get_project(project_id)
            lines = line_svc.get_all_lines(chapter_id)

            # è¿‡æ»¤æœ‰è§’è‰²ç»‘å®šçš„å°è¯
            valid_lines = [l for l in lines if l.role_id is not None]

            await manager.broadcast(
                {
                    "event": "batch_tts_chapter_start",
                    "project_id": project_id,
                    "chapter_id": chapter_id,
                    "chapter_index": ch_idx + 1,
                    "total_chapters": total_chapters,
                    "line_count": len(valid_lines),
                    "log": f"ğŸ“– ç« èŠ‚ {chapter_id} å¼€å§‹é…éŸ³ ({ch_idx + 1}/{total_chapters})ï¼Œå…± {len(valid_lines)} æ¡å°è¯",
                }
            )

            for line_idx, line in enumerate(valid_lines):
                try:
                    role = role_svc.get_role(line.role_id)
                    if not role or not role.default_voice_id:
                        await manager.broadcast(
                            {
                                "event": "batch_tts_log",
                                "project_id": project_id,
                                "chapter_id": chapter_id,
                                "line_id": line.id,
                                "log": f"âš ï¸ å°è¯ {line.id} è§’è‰²æœªç»‘å®šéŸ³è‰²ï¼Œè·³è¿‡",
                            }
                        )
                        done_lines += 1
                        continue

                    voice = voice_svc.get_voice(role.default_voice_id)
                    reference_path = voice.reference_path

                    # è·å–æƒ…ç»ªå‘é‡
                    emotion = (
                        emotion_svc.get_emotion(line.emotion_id)
                        if line.emotion_id
                        else None
                    )
                    strength = (
                        strength_svc.get_strength(line.strength_id)
                        if line.strength_id
                        else None
                    )
                    emo_vector = emotion_text_to_vector(
                        emotion.name if emotion else "å¹³é™",
                        strength.name if strength else "ä¸­ç­‰",
                    )

                    await manager.broadcast(
                        {
                            "event": "batch_tts_line_progress",
                            "project_id": project_id,
                            "chapter_id": chapter_id,
                            "line_id": line.id,
                            "line_index": line_idx + 1,
                            "line_total": len(valid_lines),
                            "overall_done": done_lines,
                            "overall_total": total_lines,
                            "progress": round((done_lines / max(total_lines, 1)) * 100),
                            "status": "processing",
                            "log": f"ğŸ”Š ç”Ÿæˆå°è¯ {line.id}: {line.text_content[:30]}...",
                        }
                    )

                    # æ‰§è¡Œ TTS
                    loop = asyncio.get_running_loop()
                    await loop.run_in_executor(
                        None,
                        line_svc.generate_audio,
                        reference_path,
                        project.tts_provider_id,
                        line.text_content,
                        None,  # emo_text
                        emo_vector,
                        line.audio_path,
                    )

                    # é€Ÿåº¦è°ƒèŠ‚
                    if (
                        speed != 1.0
                        and line.audio_path
                        and os.path.exists(line.audio_path)
                    ):
                        line_svc.process_audio_ffmpeg(line.audio_path, speed=speed)

                    line_svc.update_line(line.id, {"status": "done"})
                    done_lines += 1

                    await manager.broadcast(
                        {
                            "event": "batch_tts_line_progress",
                            "project_id": project_id,
                            "chapter_id": chapter_id,
                            "line_id": line.id,
                            "line_index": line_idx + 1,
                            "line_total": len(valid_lines),
                            "overall_done": done_lines,
                            "overall_total": total_lines,
                            "progress": round((done_lines / max(total_lines, 1)) * 100),
                            "status": "done",
                            "log": f"âœ… å°è¯ {line.id} é…éŸ³å®Œæˆ",
                        }
                    )

                except Exception as e:
                    done_lines += 1
                    logger.error(f"TTSç”Ÿæˆå¤±è´¥: {e}")
                    try:
                        line_svc.update_line(line.id, {"status": "failed"})
                    except Exception:
                        pass
                    await manager.broadcast(
                        {
                            "event": "batch_tts_line_progress",
                            "project_id": project_id,
                            "chapter_id": chapter_id,
                            "line_id": line.id,
                            "overall_done": done_lines,
                            "overall_total": total_lines,
                            "progress": round((done_lines / max(total_lines, 1)) * 100),
                            "status": "failed",
                            "log": f"âŒ å°è¯ {line.id} é…éŸ³å¤±è´¥: {e}",
                        }
                    )

            await manager.broadcast(
                {
                    "event": "batch_tts_chapter_done",
                    "project_id": project_id,
                    "chapter_id": chapter_id,
                    "chapter_index": ch_idx + 1,
                    "total_chapters": total_chapters,
                    "log": f"âœ… ç« èŠ‚ {chapter_id} é…éŸ³å®Œæˆ",
                }
            )

        except Exception as e:
            logger.error(f"æ‰¹é‡TTSå¤„ç†å¼‚å¸¸: {e}\n{traceback.format_exc()}")
            await manager.broadcast(
                {
                    "event": "batch_tts_log",
                    "project_id": project_id,
                    "chapter_id": chapter_id,
                    "log": f"âŒ ç« èŠ‚ {chapter_id} é…éŸ³å¼‚å¸¸: {e}",
                }
            )
        finally:
            db.close()

    # å…¨éƒ¨å®Œæˆ
    await manager.broadcast(
        {
            "event": "batch_tts_complete",
            "project_id": project_id,
            "total_chapters": total_chapters,
            "total_lines": total_lines,
            "log": f"ğŸ‰ æ‰¹é‡é…éŸ³å…¨éƒ¨å®Œæˆï¼å…±å¤„ç† {total_chapters} ç« , {done_lines} æ¡å°è¯",
        }
    )


# ============================================================
# è¯­éŸ³è°ƒè¯• / é¢„è§ˆ
# ============================================================


@router.post(
    "/voice-preview",
    response_model=Res,
    summary="è¯­éŸ³é¢„è§ˆ",
    description="ç”Ÿæˆè¯­éŸ³é¢„è§ˆï¼Œæ”¯æŒé€Ÿåº¦è°ƒèŠ‚",
)
async def voice_preview(req: VoicePreviewRequest, db: Session = Depends(get_db)):
    """å•ç‹¬çš„è¯­éŸ³é¢„è§ˆ/è°ƒè¯•æ¥å£"""
    try:
        services = _get_services(db)
        voice = services["voice"].get_voice(req.voice_id)
        if not voice:
            return Res(code=404, message="éŸ³è‰²ä¸å­˜åœ¨")

        # ç”Ÿæˆä¸´æ—¶éŸ³é¢‘
        preview_dir = os.path.join(get_data_dir(), "previews")
        os.makedirs(preview_dir, exist_ok=True)

        import hashlib

        text_hash = hashlib.md5(
            f"{req.text}{req.voice_id}{req.emotion_name}{req.speed}".encode()
        ).hexdigest()[:12]
        preview_path = os.path.join(preview_dir, f"preview_{text_hash}.wav")

        emo_vector = emotion_text_to_vector(req.emotion_name, req.strength_name)

        line_svc = services["line"]
        loop = asyncio.get_running_loop()
        await loop.run_in_executor(
            None,
            lambda: line_svc.generate_audio(
                voice.reference_path,
                req.tts_provider_id,
                req.text,
                None,
                emo_vector,
                preview_path,
                language=req.language,
            ),
        )

        # é€Ÿåº¦è°ƒèŠ‚
        if req.speed != 1.0 and os.path.exists(preview_path):
            line_svc.process_audio_ffmpeg(preview_path, speed=req.speed)

        # è¿”å›å¯è®¿é—®çš„éŸ³é¢‘è·¯å¾„
        relative_path = os.path.relpath(preview_path, get_data_dir())
        audio_url = f"/static/audio/{relative_path}"

        return Res(
            code=200,
            message="é¢„è§ˆç”ŸæˆæˆåŠŸ",
            data={
                "audio_url": audio_url,
                "audio_path": preview_path,
            },
        )

    except Exception as e:
        logger.error(f"è¯­éŸ³é¢„è§ˆå¤±è´¥: {e}\n{traceback.format_exc()}")
        return Res(code=500, message=f"è¯­éŸ³é¢„è§ˆå¤±è´¥: {e}")


@router.post(
    "/voice-debug",
    response_model=Res,
    summary="è¯­éŸ³è°ƒè¯•",
    description="ç‹¬ç«‹çš„è¯­éŸ³è°ƒè¯•æ¥å£ï¼Œä¸å…³è”ä¸šåŠ¡",
)
async def voice_debug(req: VoiceDebugRequest, db: Session = Depends(get_db)):
    """ç‹¬ç«‹çš„è¯­éŸ³è°ƒè¯•é¡µé¢ä½¿ç”¨çš„æ¥å£"""
    try:
        services = _get_services(db)
        voice = services["voice"].get_voice(req.voice_id)
        if not voice:
            return Res(code=404, message="éŸ³è‰²ä¸å­˜åœ¨")

        # ç”Ÿæˆè°ƒè¯•éŸ³é¢‘
        debug_dir = os.path.join(get_data_dir(), "debug")
        os.makedirs(debug_dir, exist_ok=True)

        import time

        debug_path = os.path.join(debug_dir, f"debug_{int(time.time() * 1000)}.wav")

        emo_vector = emotion_text_to_vector(req.emotion_name, req.strength_name)

        line_svc = services["line"]
        loop = asyncio.get_running_loop()
        await loop.run_in_executor(
            None,
            lambda: line_svc.generate_audio(
                voice.reference_path,
                req.tts_provider_id,
                req.text,
                None,
                emo_vector,
                debug_path,
                language=req.language,
            ),
        )

        # é€Ÿåº¦è°ƒèŠ‚
        if req.speed != 1.0 and os.path.exists(debug_path):
            line_svc.process_audio_ffmpeg(debug_path, speed=req.speed)

        relative_path = os.path.relpath(debug_path, get_data_dir())
        audio_url = f"/static/audio/{relative_path}"

        return Res(
            code=200,
            message="è°ƒè¯•éŸ³é¢‘ç”ŸæˆæˆåŠŸ",
            data={
                "audio_url": audio_url,
                "audio_path": debug_path,
                "text": req.text,
                "voice_name": voice.name,
                "emotion": req.emotion_name,
                "strength": req.strength_name,
                "speed": req.speed,
            },
        )

    except Exception as e:
        logger.error(f"è¯­éŸ³è°ƒè¯•å¤±è´¥: {e}\n{traceback.format_exc()}")
        return Res(code=500, message=f"è¯­éŸ³è°ƒè¯•å¤±è´¥: {e}")


# ============================================================
# è¯­éŸ³é€Ÿåº¦è°ƒèŠ‚
# ============================================================


class SpeedAdjustRequest(BaseModel):
    """é€Ÿåº¦è°ƒèŠ‚è¯·æ±‚"""

    line_id: int
    speed: float  # 0.5 ~ 2.0


class BatchSpeedAdjustRequest(BaseModel):
    """æ‰¹é‡é€Ÿåº¦è°ƒèŠ‚è¯·æ±‚"""

    chapter_id: int
    speed: float  # 0.5 ~ 2.0


@router.post("/adjust-speed", response_model=Res, summary="å•æ¡å°è¯é€Ÿåº¦è°ƒèŠ‚")
async def adjust_speed(req: SpeedAdjustRequest, db: Session = Depends(get_db)):
    """è°ƒæ•´å•æ¡å°è¯çš„è¯­é€Ÿ"""
    try:
        services = _get_services(db)
        line = services["line"].get_line(req.line_id)
        if not line or not line.audio_path or not os.path.exists(line.audio_path):
            return Res(code=404, message="å°è¯éŸ³é¢‘ä¸å­˜åœ¨")

        services["line"].process_audio_ffmpeg(line.audio_path, speed=req.speed)

        relative_path = os.path.relpath(line.audio_path, get_data_dir())
        audio_url = f"/static/audio/{relative_path}"

        return Res(code=200, message="é€Ÿåº¦è°ƒèŠ‚å®Œæˆ", data={"audio_url": audio_url})
    except Exception as e:
        return Res(code=500, message=f"é€Ÿåº¦è°ƒèŠ‚å¤±è´¥: {e}")


@router.post(
    "/batch-adjust-speed",
    response_model=Res,
    summary="æ‰¹é‡é€Ÿåº¦è°ƒèŠ‚",
    description="è°ƒæ•´æ•´ä¸ªç« èŠ‚æ‰€æœ‰å°è¯çš„è¯­é€Ÿ",
)
async def batch_adjust_speed(
    req: BatchSpeedAdjustRequest, db: Session = Depends(get_db)
):
    """æ‰¹é‡è°ƒæ•´ç« èŠ‚å†…æ‰€æœ‰å°è¯çš„è¯­é€Ÿ"""
    try:
        services = _get_services(db)
        lines = services["line"].get_all_lines(req.chapter_id)
        adjusted = 0
        for line in lines:
            if line.audio_path and os.path.exists(line.audio_path):
                services["line"].process_audio_ffmpeg(line.audio_path, speed=req.speed)
                adjusted += 1

        return Res(
            code=200,
            message=f"æ‰¹é‡é€Ÿåº¦è°ƒèŠ‚å®Œæˆï¼Œè°ƒæ•´äº† {adjusted} æ¡å°è¯",
            data={"adjusted": adjusted},
        )
    except Exception as e:
        return Res(code=500, message=f"æ‰¹é‡é€Ÿåº¦è°ƒèŠ‚å¤±è´¥: {e}")


# ============================================================
# ä¸€é”®æŒ‚æœºï¼ˆAutopilotï¼‰ï¼šLLM â†’ æ™ºèƒ½éŸ³è‰² â†’ TTS å…¨è‡ªåŠ¨æµæ°´çº¿
# ============================================================


class AutopilotRequest(BaseModel):
    """ä¸€é”®æŒ‚æœºè¯·æ±‚"""

    project_id: int
    chapter_ids: List[int]
    concurrency: int = 1  # LLM å¹¶å‘æ•°
    speed: float = 1.0  # TTS å…¨å±€é€Ÿåº¦
    voice_match_interval: int = 10  # æ¯éš”å¤šå°‘ç« åšä¸€æ¬¡æ™ºèƒ½éŸ³è‰²åŒ¹é…
    manual_voice_assign: bool = (
        False  # æ˜¯å¦æ‰‹åŠ¨åˆ†é…éŸ³è‰²ï¼ˆè·³è¿‡æ™ºèƒ½åŒ¹é…ï¼Œç›´æ¥æš‚åœè®©ç”¨æˆ·åˆ†é…ï¼‰
    )


# å­˜å‚¨è¿è¡Œä¸­çš„æŒ‚æœºä»»åŠ¡: project_id -> task_info
_autopilot_tasks: dict = {}


@router.post(
    "/autopilot-start",
    response_model=Res,
    summary="ä¸€é”®æŒ‚æœºå¯åŠ¨",
    description="è‡ªåŠ¨æ‰§è¡Œ LLMè§£æ â†’ æ™ºèƒ½éŸ³è‰²åŒ¹é… â†’ TTSé…éŸ³ çš„å…¨æµç¨‹ï¼Œæ”¯æŒæš‚åœ/ç»§ç»­",
)
async def autopilot_start(req: AutopilotRequest):
    """å¯åŠ¨ä¸€é”®æŒ‚æœºä»»åŠ¡"""
    if req.project_id in _autopilot_tasks:
        return Res(code=400, message="è¯¥é¡¹ç›®å·²æœ‰æŒ‚æœºä»»åŠ¡åœ¨è¿è¡Œä¸­ï¼Œè¯·å…ˆå–æ¶ˆåå†é‡è¯•")

    concurrency = max(1, min(10, req.concurrency))
    cancel_event = asyncio.Event()
    pause_event = asyncio.Event()  # set = æš‚åœä¸­
    resume_event = asyncio.Event()  # set = å¯ä»¥ç»§ç»­
    resume_event.set()  # é»˜è®¤ä¸æš‚åœ

    task = asyncio.create_task(
        _do_autopilot(
            req.project_id,
            req.chapter_ids,
            concurrency,
            req.speed,
            req.voice_match_interval,
            req.manual_voice_assign,
            cancel_event,
            pause_event,
            resume_event,
        )
    )

    _autopilot_tasks[req.project_id] = {
        "cancel_event": cancel_event,
        "pause_event": pause_event,
        "resume_event": resume_event,
        "task": task,
        "chapter_ids": req.chapter_ids,
    }

    def _cleanup(fut):
        _autopilot_tasks.pop(req.project_id, None)

    task.add_done_callback(_cleanup)

    return Res(
        code=200,
        message="ä¸€é”®æŒ‚æœºä»»åŠ¡å·²å¯åŠ¨",
        data={
            "chapter_count": len(req.chapter_ids),
            "concurrency": concurrency,
            "voice_match_interval": req.voice_match_interval,
        },
    )


@router.get(
    "/autopilot-status",
    response_model=Res,
    summary="æŸ¥è¯¢æŒ‚æœºä»»åŠ¡çŠ¶æ€",
)
async def autopilot_status(project_id: int):
    """æŸ¥è¯¢ä¸€é”®æŒ‚æœºä»»åŠ¡æ˜¯å¦æ­£åœ¨è¿è¡Œ"""
    task_info = _autopilot_tasks.get(project_id)
    if not task_info:
        return Res(code=200, message="æ— è¿è¡Œä¸­çš„ä»»åŠ¡", data={"running": False})

    return Res(
        code=200,
        message="ä»»åŠ¡è¿è¡Œä¸­",
        data={
            "running": True,
            "paused": task_info["pause_event"].is_set(),
            "cancelled": task_info["cancel_event"].is_set(),
        },
    )


@router.post(
    "/autopilot-pause",
    response_model=Res,
    summary="æš‚åœæŒ‚æœºä»»åŠ¡",
    description="æš‚åœä¸€é”®æŒ‚æœºä»»åŠ¡ï¼Œå½“å‰ç« èŠ‚ä¼šå¤„ç†å®Œå†æš‚åœ",
)
async def autopilot_pause(project_id: int):
    """æš‚åœä¸€é”®æŒ‚æœºä»»åŠ¡"""
    task_info = _autopilot_tasks.get(project_id)
    if not task_info:
        return Res(code=404, message="æ²¡æœ‰æ­£åœ¨è¿è¡Œçš„æŒ‚æœºä»»åŠ¡")

    task_info["pause_event"].set()
    task_info["resume_event"].clear()
    logger.info(f"æŒ‚æœºä»»åŠ¡æš‚åœä¿¡å·å·²å‘é€: project_id={project_id}")

    await manager.broadcast(
        {
            "event": "autopilot_log",
            "project_id": project_id,
            "log": "â¸ï¸ æš‚åœä¿¡å·å·²å‘é€ï¼Œå½“å‰ç« èŠ‚å¤„ç†å®Œåæš‚åœ",
        }
    )
    return Res(code=200, message="æš‚åœä¿¡å·å·²å‘é€ï¼Œå½“å‰ç« èŠ‚å¤„ç†å®Œåæš‚åœ")


@router.post(
    "/autopilot-resume",
    response_model=Res,
    summary="ç»§ç»­æŒ‚æœºä»»åŠ¡",
    description="ç»§ç»­å·²æš‚åœçš„ä¸€é”®æŒ‚æœºä»»åŠ¡",
)
async def autopilot_resume(project_id: int):
    """ç»§ç»­å·²æš‚åœçš„ä¸€é”®æŒ‚æœºä»»åŠ¡"""
    task_info = _autopilot_tasks.get(project_id)
    if not task_info:
        return Res(code=404, message="æ²¡æœ‰æ­£åœ¨è¿è¡Œçš„æŒ‚æœºä»»åŠ¡")

    task_info["pause_event"].clear()
    task_info["resume_event"].set()
    logger.info(f"æŒ‚æœºä»»åŠ¡ç»§ç»­ä¿¡å·å·²å‘é€: project_id={project_id}")

    await manager.broadcast(
        {
            "event": "autopilot_log",
            "project_id": project_id,
            "log": "â–¶ï¸ ä»»åŠ¡å·²ç»§ç»­",
        }
    )
    return Res(code=200, message="ä»»åŠ¡å·²ç»§ç»­")


@router.post(
    "/autopilot-cancel",
    response_model=Res,
    summary="å–æ¶ˆæŒ‚æœºä»»åŠ¡",
)
async def autopilot_cancel(project_id: int):
    """å–æ¶ˆä¸€é”®æŒ‚æœºä»»åŠ¡"""
    task_info = _autopilot_tasks.get(project_id)
    if not task_info:
        return Res(code=404, message="æ²¡æœ‰æ­£åœ¨è¿è¡Œçš„æŒ‚æœºä»»åŠ¡")

    task_info["cancel_event"].set()
    # å¦‚æœæš‚åœä¸­ï¼Œä¹Ÿè¦å”¤é†’è®©å®ƒé€€å‡º
    task_info["resume_event"].set()
    logger.info(f"æŒ‚æœºä»»åŠ¡å–æ¶ˆä¿¡å·å·²å‘é€: project_id={project_id}")
    return Res(code=200, message="å–æ¶ˆä¿¡å·å·²å‘é€")


# ---- ä¸€é”®æŒ‚æœºæ ¸å¿ƒé€»è¾‘ ----


async def _autopilot_wait_resume(
    project_id: int,
    pause_event: asyncio.Event,
    resume_event: asyncio.Event,
    cancel_event: asyncio.Event,
) -> bool:
    """
    æ£€æŸ¥æ˜¯å¦æš‚åœï¼Œå¦‚æœæš‚åœåˆ™ç­‰å¾…æ¢å¤ã€‚
    è¿”å› True è¡¨ç¤ºå¯ä»¥ç»§ç»­ï¼ŒFalse è¡¨ç¤ºå·²å–æ¶ˆã€‚
    """
    if cancel_event.is_set():
        return False

    if pause_event.is_set():
        await manager.broadcast(
            {
                "event": "autopilot_paused",
                "project_id": project_id,
                "log": "â¸ï¸ ä»»åŠ¡å·²æš‚åœï¼Œç­‰å¾…ç”¨æˆ·ç»§ç»­...",
            }
        )
        # asyncio.Event.wait æ˜¯éé˜»å¡åç¨‹ï¼Œæ— éœ€çº¿ç¨‹æ± 
        await resume_event.wait()
        if cancel_event.is_set():
            return False
        await manager.broadcast(
            {
                "event": "autopilot_resumed",
                "project_id": project_id,
                "log": "â–¶ï¸ ä»»åŠ¡å·²æ¢å¤",
            }
        )
    return True


async def _autopilot_llm_single_chapter(
    project_id: int,
    chapter_id: int,
    cancel_event: asyncio.Event,
) -> bool:
    """
    å¯¹å•ä¸ªç« èŠ‚æ‰§è¡Œ LLM è§£æï¼ˆçº¯åç¨‹ï¼Œå¤ç”¨ _process_single_chapter_asyncï¼‰ã€‚
    è¿”å› True=æˆåŠŸ, False=å¤±è´¥æˆ–å–æ¶ˆã€‚
    """
    done_counter = {"done": 0}

    # ä¸´æ—¶æ›¿æ¢ manager.broadcast æ¥æ•è·äº‹ä»¶å¹¶æ”¹å†™å‰ç¼€
    original_broadcast = manager.broadcast
    success = False

    async def _intercepted_broadcast(msg: dict):
        nonlocal success
        original_event = msg.get("event", "")
        if original_event == "batch_llm_progress":
            msg["event"] = "autopilot_llm_progress"
            if msg.get("status") == "done":
                success = True
        elif original_event == "batch_llm_log":
            msg["event"] = "autopilot_llm_log"
        await original_broadcast(msg)

    manager.broadcast = _intercepted_broadcast
    try:
        await _process_single_chapter_async(
            project_id,
            chapter_id,
            0,  # idx
            1,  # total
            cancel_event,
            done_counter,
        )
    finally:
        manager.broadcast = original_broadcast

    return success


async def _autopilot_tts_single_chapter(
    project_id: int,
    chapter_id: int,
    speed: float,
    cancel_event: asyncio.Event,
) -> bool:
    """
    å¯¹å•ä¸ªç« èŠ‚æ‰§è¡Œ TTS é…éŸ³ã€‚
    è¿”å› True=æˆåŠŸï¼ˆæ‰€æœ‰å°è¯é…éŸ³å®Œæˆï¼‰, False=æœ‰å¤±è´¥ã€‚
    """
    db = SessionLocal()
    has_failure = False
    try:
        services = _get_services(db)
        line_svc = services["line"]
        role_svc = services["role"]
        voice_svc = services["voice"]
        emotion_svc = services["emotion"]
        strength_svc = services["strength"]
        project_svc = services["project"]

        project = project_svc.get_project(project_id)
        lines = line_svc.get_all_lines(chapter_id)
        valid_lines = [l for l in lines if l.role_id is not None]

        await manager.broadcast(
            {
                "event": "autopilot_tts_chapter_start",
                "project_id": project_id,
                "chapter_id": chapter_id,
                "line_count": len(valid_lines),
                "log": f"ğŸ™ï¸ ç« èŠ‚ {chapter_id} å¼€å§‹é…éŸ³ï¼Œå…± {len(valid_lines)} æ¡å°è¯",
            }
        )

        done_count = 0
        for line_idx, line in enumerate(valid_lines):
            if cancel_event.is_set():
                return False

            try:
                role = role_svc.get_role(line.role_id)
                if not role or not role.default_voice_id:
                    await manager.broadcast(
                        {
                            "event": "autopilot_tts_log",
                            "project_id": project_id,
                            "chapter_id": chapter_id,
                            "log": f"âš ï¸ å°è¯ {line.id} è§’è‰²æœªç»‘å®šéŸ³è‰²ï¼Œè·³è¿‡",
                        }
                    )
                    done_count += 1
                    continue

                voice = voice_svc.get_voice(role.default_voice_id)
                reference_path = voice.reference_path

                emotion = (
                    emotion_svc.get_emotion(line.emotion_id)
                    if line.emotion_id
                    else None
                )
                strength = (
                    strength_svc.get_strength(line.strength_id)
                    if line.strength_id
                    else None
                )
                emo_vector = emotion_text_to_vector(
                    emotion.name if emotion else "å¹³é™",
                    strength.name if strength else "ä¸­ç­‰",
                )

                await manager.broadcast(
                    {
                        "event": "autopilot_tts_line",
                        "project_id": project_id,
                        "chapter_id": chapter_id,
                        "line_index": line_idx + 1,
                        "line_total": len(valid_lines),
                        "log": f"ğŸ”Š [{line_idx+1}/{len(valid_lines)}] {line.text_content[:30]}...",
                    }
                )

                loop = asyncio.get_running_loop()
                await loop.run_in_executor(
                    None,
                    line_svc.generate_audio,
                    reference_path,
                    project.tts_provider_id,
                    line.text_content,
                    None,
                    emo_vector,
                    line.audio_path,
                )

                if speed != 1.0 and line.audio_path and os.path.exists(line.audio_path):
                    line_svc.process_audio_ffmpeg(line.audio_path, speed=speed)

                line_svc.update_line(line.id, {"status": "done"})
                done_count += 1

            except Exception as e:
                done_count += 1
                has_failure = True
                logger.error(f"TTSç”Ÿæˆå¤±è´¥: {e}")
                try:
                    line_svc.update_line(line.id, {"status": "failed"})
                except Exception:
                    pass
                await manager.broadcast(
                    {
                        "event": "autopilot_tts_log",
                        "project_id": project_id,
                        "chapter_id": chapter_id,
                        "log": f"âŒ å°è¯ {line.id} é…éŸ³å¤±è´¥: {e}",
                    }
                )

        await manager.broadcast(
            {
                "event": "autopilot_tts_chapter_done",
                "project_id": project_id,
                "chapter_id": chapter_id,
                "log": f"âœ… ç« èŠ‚ {chapter_id} é…éŸ³å®Œæˆ ({done_count}/{len(valid_lines)})",
            }
        )
        return not has_failure

    except Exception as e:
        logger.error(f"æŒ‚æœºTTSå¼‚å¸¸: {e}\n{traceback.format_exc()}")
        await manager.broadcast(
            {
                "event": "autopilot_tts_log",
                "project_id": project_id,
                "chapter_id": chapter_id,
                "log": f"âŒ ç« èŠ‚ {chapter_id} é…éŸ³å¼‚å¸¸: {e}",
            }
        )
        return False
    finally:
        db.close()


async def _autopilot_smart_voice_match(project_id: int) -> dict:
    """
    å¯¹é¡¹ç›®æ‰§è¡Œæ™ºèƒ½éŸ³è‰²åŒ¹é…ï¼ˆä¸ºæœªç»‘å®šéŸ³è‰²çš„è§’è‰²è‡ªåŠ¨åˆ†é…ï¼‰ã€‚
    è¿”å› {"success": bool, "unmatched_roles": [...], "matched": [...]}
    """
    db = SessionLocal()
    try:
        services = _get_services(db)
        role_svc = services["role"]
        voice_svc = services["voice"]
        project_svc = services["project"]
        chapter_svc = services["chapter"]

        project = project_svc.get_project(project_id)
        roles = role_svc.get_all_roles(project_id)

        # æœªç»‘å®šéŸ³è‰²çš„è§’è‰²
        unbound_roles = [r for r in roles if r.default_voice_id is None]
        if not unbound_roles:
            return {"success": True, "unmatched_roles": [], "matched": []}

        unbound_names = [r.name for r in unbound_roles]

        # è·å–æ‰€æœ‰éŸ³è‰²
        voices = voice_svc.get_all_voices(project.tts_provider_id)
        voice_names = [{"name": v.name, "description": v.description} for v in voices]
        voice_id_map = {v.name: v.id for v in voices}

        # ä½¿ç”¨é¡¹ç›®çš„ LLM è¿›è¡Œæ™ºèƒ½åŒ¹é…
        from py.core.prompts import get_add_smart_role_and_voice
        from py.core.llm_engine import LLMEngine
        from py.repositories.llm_provider_repository import LLMProviderRepository

        llm_repo = LLMProviderRepository(db)
        llm_provider = llm_repo.get_by_id(project.llm_provider_id)
        llm = LLMEngine(
            llm_provider.api_key,
            llm_provider.api_base_url,
            project.llm_model,
            llm_provider.custom_params,
        )

        # è·å–é¡¹ç›®ä¸‹æ‰€æœ‰ç« èŠ‚çš„é¦–ç« æ–‡æœ¬ä½œä¸ºä¸Šä¸‹æ–‡ï¼ˆç®€åŒ–å¤„ç†ï¼‰
        all_chapters = chapter_svc.get_all_chapters(project_id)
        # æ‹¿ç¬¬ä¸€ä¸ªæœ‰å†…å®¹çš„ç« èŠ‚ä½œä¸ºä¸Šä¸‹æ–‡
        context_text = ""
        for ch_info in all_chapters[:5]:  # æœ€å¤šçœ‹å‰5ç« 
            ch = chapter_svc.get_chapter(ch_info["id"])
            if ch and ch.text_content:
                context_text += ch.text_content[:500] + "\n"
            if len(context_text) > 2000:
                break

        prompt = get_add_smart_role_and_voice(context_text, unbound_names, voice_names)
        result = await llm.generate_smart_text_async(prompt)
        parse_data = await llm.save_load_json_async(result)

        matched = []
        still_unmatched = list(unbound_names)

        from py.repositories.role_repository import RoleRepository

        role_repo = RoleRepository(db)

        if parse_data:
            for item in parse_data:
                role_name = item.get("role_name", "")
                voice_name = item.get("voice_name", "")
                if role_name and voice_name and voice_name in voice_id_map:
                    role = role_repo.get_by_name(role_name, project_id)
                    if role:
                        role_repo.update(
                            role.id,
                            {"default_voice_id": voice_id_map[voice_name]},
                        )
                        matched.append(
                            {"role_name": role_name, "voice_name": voice_name}
                        )
                        if role_name in still_unmatched:
                            still_unmatched.remove(role_name)

        return {
            "success": len(still_unmatched) == 0,
            "unmatched_roles": still_unmatched,
            "matched": matched,
        }

    except Exception as e:
        logger.error(f"æ™ºèƒ½éŸ³è‰²åŒ¹é…å¤±è´¥: {e}\n{traceback.format_exc()}")
        return {"success": False, "unmatched_roles": [], "matched": [], "error": str(e)}
    finally:
        db.close()


def _check_chapter_unbound_roles(project_id: int, chapter_id: int) -> list:
    """
    æ£€æŸ¥æŸç« èŠ‚çš„å°è¯ä¸­ï¼Œæ˜¯å¦æœ‰è§’è‰²æœªç»‘å®šéŸ³è‰²ã€‚
    è¿”å›æœªç»‘å®šçš„è§’è‰²åç§°åˆ—è¡¨ã€‚
    """
    db = SessionLocal()
    try:
        services = _get_services(db)
        line_svc = services["line"]
        role_svc = services["role"]

        lines = line_svc.get_all_lines(chapter_id)
        unbound_role_names = []
        seen_role_ids = set()

        for line in lines:
            if line.role_id and line.role_id not in seen_role_ids:
                seen_role_ids.add(line.role_id)
                role = role_svc.get_role(line.role_id)
                if role and not role.default_voice_id:
                    unbound_role_names.append(role.name)

        return unbound_role_names
    finally:
        db.close()


async def _do_autopilot(
    project_id: int,
    chapter_ids: List[int],
    concurrency: int,
    speed: float,
    voice_match_interval: int,
    manual_voice_assign: bool,
    cancel_event: asyncio.Event,
    pause_event: asyncio.Event,
    resume_event: asyncio.Event,
):
    """
    ä¸€é”®æŒ‚æœºæ ¸å¿ƒæµç¨‹ï¼ˆå¹¶è¡Œæµæ°´çº¿æ¨¡å¼ï¼‰ï¼š
    - LLM Producerï¼šå¹¶å‘æ‰§è¡Œ LLM è§£æï¼Œå®Œæˆåå°†ç« èŠ‚æ”¾å…¥ tts_queue
    - TTS Consumerï¼šä» tts_queue å–ç« èŠ‚ï¼Œæ£€æŸ¥éŸ³è‰²åæ‰§è¡Œ TTS
    - ä¸¤è€…é€šè¿‡ asyncio.Queue åä½œï¼ŒåŒæ—¶è¿è¡Œ
    - æ¯ voice_match_interval ç« åšä¸€æ¬¡æ™ºèƒ½éŸ³è‰²åŒ¹é…
    - æ”¯æŒæš‚åœ/ç»§ç»­/å–æ¶ˆ
    """
    total = len(chapter_ids)
    llm_done_count = 0
    tts_done_count = 0
    # è¿½è¸ªè‡ªä¸Šæ¬¡æ™ºèƒ½åŒ¹é…åå·²å¤„ç†çš„ç« èŠ‚æ•°
    chapters_since_last_match = 0
    # LLM å®Œæˆåæ”¾å…¥æ­¤é˜Ÿåˆ—ï¼ŒTTS Consumer ä»ä¸­å–
    # é˜Ÿåˆ—å…ƒç´ : (chapter_id, ch_idx, llm_success)
    tts_queue: asyncio.Queue = asyncio.Queue()
    # ç”¨äºéŸ³è‰²åŒ¹é…çš„é”ï¼ˆé˜²æ­¢å¤šä¸ª LLM worker åŒæ—¶è§¦å‘åŒ¹é…ï¼‰
    voice_match_lock = asyncio.Lock()

    await manager.broadcast(
        {
            "event": "autopilot_start",
            "project_id": project_id,
            "total": total,
            "log": f"ğŸš€ ä¸€é”®æŒ‚æœºå·²å¯åŠ¨ï¼ˆå¹¶è¡Œæµæ°´çº¿ï¼‰ï¼šå…± {total} ç« ï¼ŒLLMå¹¶å‘æ•° {concurrency}ï¼Œæ¯ {voice_match_interval} ç« åŒ¹é…éŸ³è‰²",
        }
    )

    # ---- LLM Producerï¼šå¹¶å‘æ‰§è¡Œ LLM è§£æ ----
    semaphore = asyncio.Semaphore(concurrency)

    async def _llm_worker(chapter_id: int, ch_idx: int):
        """å•ä¸ª LLM ä»»åŠ¡ï¼šè§£æå®Œæˆåæ”¾å…¥ TTS é˜Ÿåˆ—"""
        nonlocal llm_done_count, chapters_since_last_match

        # æ£€æŸ¥æš‚åœ/å–æ¶ˆ
        can_continue = await _autopilot_wait_resume(
            project_id, pause_event, resume_event, cancel_event
        )
        if not can_continue:
            return

        async with semaphore:
            if cancel_event.is_set():
                return

            await manager.broadcast(
                {
                    "event": "autopilot_progress",
                    "project_id": project_id,
                    "phase": "llm",
                    "chapter_id": chapter_id,
                    "llm_done": llm_done_count,
                    "tts_done": tts_done_count,
                    "total": total,
                    "log": f"ğŸ“– [{ch_idx+1}/{total}] ç« èŠ‚ {chapter_id} å¼€å§‹ LLM è§£æ",
                }
            )

            llm_success = await _autopilot_llm_single_chapter(
                project_id, chapter_id, cancel_event
            )

            if cancel_event.is_set():
                return

            if llm_success:
                llm_done_count += 1
                chapters_since_last_match += 1

                await manager.broadcast(
                    {
                        "event": "autopilot_progress",
                        "project_id": project_id,
                        "phase": "llm_done",
                        "chapter_id": chapter_id,
                        "llm_done": llm_done_count,
                        "tts_done": tts_done_count,
                        "total": total,
                        "log": f"âœ… [{llm_done_count}/{total}] ç« èŠ‚ {chapter_id} LLM è§£æå®Œæˆ",
                    }
                )

                # LLM å®Œæˆåæ£€æŸ¥æ˜¯å¦éœ€è¦éŸ³è‰²åŒ¹é…ï¼ˆåŠ é”é˜²æ­¢å¹¶å‘å†²çªï¼‰
                async with voice_match_lock:
                    await _autopilot_check_voice_match(
                        project_id,
                        chapter_id,
                        chapters_since_last_match,
                        voice_match_interval,
                        manual_voice_assign,
                        pause_event,
                        resume_event,
                        cancel_event,
                    )
                    if chapters_since_last_match >= voice_match_interval:
                        chapters_since_last_match = 0

                # æ”¾å…¥ TTS é˜Ÿåˆ—
                await tts_queue.put((chapter_id, ch_idx, True))
            else:
                llm_done_count += 1  # å¤±è´¥ä¹Ÿè®¡å…¥è¿›åº¦
                await manager.broadcast(
                    {
                        "event": "autopilot_progress",
                        "project_id": project_id,
                        "phase": "llm_error",
                        "chapter_id": chapter_id,
                        "llm_done": llm_done_count,
                        "tts_done": tts_done_count,
                        "total": total,
                        "log": f"âŒ ç« èŠ‚ {chapter_id} LLM è§£æå¤±è´¥ï¼Œè·³è¿‡è¯¥ç« TTS",
                    }
                )
                # å¤±è´¥ä¹Ÿæ”¾å…¥é˜Ÿåˆ—ï¼Œæ ‡è®°ä¸ºå¤±è´¥
                await tts_queue.put((chapter_id, ch_idx, False))

            await asyncio.sleep(0.1)

    async def _llm_producer():
        """LLM ç”Ÿäº§è€…ï¼šé€ç« å‘èµ· LLM ä»»åŠ¡ï¼ˆä¿¡å·é‡æ§åˆ¶å¹¶å‘ï¼‰"""
        tasks = []
        for ch_idx, chapter_id in enumerate(chapter_ids):
            if cancel_event.is_set():
                break
            task = asyncio.create_task(_llm_worker(chapter_id, ch_idx))
            tasks.append(task)

        # ç­‰å¾…æ‰€æœ‰ LLM ä»»åŠ¡å®Œæˆ
        if tasks:
            await asyncio.gather(*tasks, return_exceptions=True)

        # å‘é€ç»“æŸå“¨å…µï¼Œå‘ŠçŸ¥ TTS Consumer æ‰€æœ‰ LLM éƒ½å®Œæˆäº†
        await tts_queue.put(None)

    # ---- TTS Consumerï¼šä»é˜Ÿåˆ—å–ç« èŠ‚æ‰§è¡Œ TTS ----
    async def _tts_consumer():
        """TTS æ¶ˆè´¹è€…ï¼šä¸²è¡Œä»é˜Ÿåˆ—å–ç« èŠ‚æ‰§è¡Œ TTS é…éŸ³"""
        nonlocal tts_done_count

        while True:
            if cancel_event.is_set():
                break

            # ä»é˜Ÿåˆ—è·å–ä¸‹ä¸€ä¸ªè¦é…éŸ³çš„ç« èŠ‚
            item = await tts_queue.get()

            # æ”¶åˆ°ç»“æŸå“¨å…µï¼Œé€€å‡º
            if item is None:
                break

            chapter_id, ch_idx, llm_success = item

            if cancel_event.is_set():
                break

            # LLM å¤±è´¥çš„ç« èŠ‚è·³è¿‡ TTS
            if not llm_success:
                tts_done_count += 1
                await manager.broadcast(
                    {
                        "event": "autopilot_progress",
                        "project_id": project_id,
                        "phase": "tts_error",
                        "chapter_id": chapter_id,
                        "llm_done": llm_done_count,
                        "tts_done": tts_done_count,
                        "total": total,
                        "log": f"â­ï¸ ç« èŠ‚ {chapter_id} LLMå¤±è´¥ï¼Œè·³è¿‡é…éŸ³",
                    }
                )
                continue

            # æ£€æŸ¥æš‚åœ/å–æ¶ˆ
            can_continue = await _autopilot_wait_resume(
                project_id, pause_event, resume_event, cancel_event
            )
            if not can_continue:
                break

            # æ£€æŸ¥è¯¥ç« èŠ‚è§’è‰²æ˜¯å¦éƒ½å·²ç»‘å®šéŸ³è‰²
            unbound_now = _check_chapter_unbound_roles(project_id, chapter_id)
            if unbound_now:
                await manager.broadcast(
                    {
                        "event": "autopilot_log",
                        "project_id": project_id,
                        "chapter_id": chapter_id,
                        "log": f"âš ï¸ ç« èŠ‚ {chapter_id} æœ‰ {len(unbound_now)} ä¸ªè§’è‰²æœªç»‘å®šéŸ³è‰²ï¼Œè·³è¿‡é…éŸ³: {', '.join(unbound_now)}",
                    }
                )
                tts_done_count += 1
                await manager.broadcast(
                    {
                        "event": "autopilot_progress",
                        "project_id": project_id,
                        "phase": "tts_error",
                        "chapter_id": chapter_id,
                        "llm_done": llm_done_count,
                        "tts_done": tts_done_count,
                        "total": total,
                        "log": f"â­ï¸ ç« èŠ‚ {chapter_id} è§’è‰²æœªç»‘å®šéŸ³è‰²ï¼Œå·²è·³è¿‡",
                    }
                )
                continue

            # æ‰§è¡Œ TTS é…éŸ³
            await manager.broadcast(
                {
                    "event": "autopilot_progress",
                    "project_id": project_id,
                    "phase": "tts",
                    "chapter_id": chapter_id,
                    "llm_done": llm_done_count,
                    "tts_done": tts_done_count,
                    "total": total,
                    "log": f"ğŸ™ï¸ ç« èŠ‚ {chapter_id} å¼€å§‹ TTS é…éŸ³",
                }
            )

            tts_success = await _autopilot_tts_single_chapter(
                project_id, chapter_id, speed, cancel_event
            )
            tts_done_count += 1

            await manager.broadcast(
                {
                    "event": "autopilot_progress",
                    "project_id": project_id,
                    "phase": "tts_done" if tts_success else "tts_error",
                    "chapter_id": chapter_id,
                    "llm_done": llm_done_count,
                    "tts_done": tts_done_count,
                    "total": total,
                    "log": f"{'âœ…' if tts_success else 'âš ï¸'} ç« èŠ‚ {chapter_id} é…éŸ³{'å®Œæˆ' if tts_success else 'æœ‰å¤±è´¥é¡¹'}",
                }
            )

    # ---- å¹¶è¡Œè¿è¡Œ LLM Producer å’Œ TTS Consumer ----
    await asyncio.gather(_llm_producer(), _tts_consumer())

    # ---- å®Œæˆ ----
    if cancel_event.is_set():
        await manager.broadcast(
            {
                "event": "autopilot_complete",
                "project_id": project_id,
                "cancelled": True,
                "llm_done": llm_done_count,
                "tts_done": tts_done_count,
                "total": total,
                "log": f"â¹ï¸ ä¸€é”®æŒ‚æœºå·²å–æ¶ˆï¼LLMå®Œæˆ {llm_done_count}/{total}ï¼ŒTTSå®Œæˆ {tts_done_count}/{total}",
            }
        )
    else:
        await manager.broadcast(
            {
                "event": "autopilot_complete",
                "project_id": project_id,
                "cancelled": False,
                "llm_done": llm_done_count,
                "tts_done": tts_done_count,
                "total": total,
                "log": f"ğŸ‰ ä¸€é”®æŒ‚æœºå…¨éƒ¨å®Œæˆï¼LLMå®Œæˆ {llm_done_count}/{total}ï¼ŒTTSå®Œæˆ {tts_done_count}/{total}",
            }
        )


async def _autopilot_check_voice_match(
    project_id: int,
    chapter_id: int,
    chapters_since_last_match: int,
    voice_match_interval: int,
    manual_voice_assign: bool,
    pause_event: asyncio.Event,
    resume_event: asyncio.Event,
    cancel_event: asyncio.Event,
):
    """
    æ£€æŸ¥æ˜¯å¦éœ€è¦è¿›è¡ŒéŸ³è‰²åŒ¹é…ï¼ˆä» _do_autopilot ä¸­æŠ½å–å‡ºæ¥çš„é€»è¾‘ï¼‰ã€‚
    åœ¨ LLM å®Œæˆåã€æ”¾å…¥ TTS é˜Ÿåˆ—å‰è°ƒç”¨ã€‚
    """
    need_voice_match = chapters_since_last_match >= voice_match_interval

    if not (need_voice_match or manual_voice_assign):
        return

    # æ£€æŸ¥æ˜¯å¦æœ‰æœªç»‘å®šéŸ³è‰²çš„è§’è‰²
    unbound = _check_chapter_unbound_roles(project_id, chapter_id)

    if not unbound:
        return

    if manual_voice_assign:
        # æ‰‹åŠ¨æ¨¡å¼ï¼šç›´æ¥æš‚åœ
        await manager.broadcast(
            {
                "event": "autopilot_voice_needed",
                "project_id": project_id,
                "chapter_id": chapter_id,
                "unbound_roles": unbound,
                "log": f"â¸ï¸ å‘ç° {len(unbound)} ä¸ªè§’è‰²æœªç»‘å®šéŸ³è‰²: {', '.join(unbound)}ï¼Œè¯·æ‰‹åŠ¨åˆ†é…åç»§ç»­",
            }
        )
        pause_event.set()
        resume_event.clear()
        # ç­‰å¾…ç”¨æˆ·ç»§ç»­
        await _autopilot_wait_resume(
            project_id, pause_event, resume_event, cancel_event
        )
    else:
        # è‡ªåŠ¨æ™ºèƒ½åŒ¹é…
        await manager.broadcast(
            {
                "event": "autopilot_log",
                "project_id": project_id,
                "log": f"ğŸ¤– æ£€æµ‹åˆ° {len(unbound)} ä¸ªæ–°è§’è‰²æœªç»‘å®šéŸ³è‰²ï¼Œå¼€å§‹æ™ºèƒ½åŒ¹é…...",
            }
        )

        match_result = await _autopilot_smart_voice_match(project_id)

        if match_result["matched"]:
            matched_str = ", ".join(
                [f"{m['role_name']}â†’{m['voice_name']}" for m in match_result["matched"]]
            )
            await manager.broadcast(
                {
                    "event": "autopilot_voice_matched",
                    "project_id": project_id,
                    "matched": match_result["matched"],
                    "log": f"âœ… æ™ºèƒ½åŒ¹é…æˆåŠŸ: {matched_str}",
                }
            )

        if match_result["unmatched_roles"]:
            # åŒ¹é…å¤±è´¥ï¼Œæš‚åœè®©ç”¨æˆ·æ‰‹åŠ¨åˆ†é…
            await manager.broadcast(
                {
                    "event": "autopilot_voice_needed",
                    "project_id": project_id,
                    "chapter_id": chapter_id,
                    "unbound_roles": match_result["unmatched_roles"],
                    "log": f"âš ï¸ ä»æœ‰ {len(match_result['unmatched_roles'])} ä¸ªè§’è‰²æœªåŒ¹é…åˆ°éŸ³è‰²: {', '.join(match_result['unmatched_roles'])}ï¼Œè¯·æ‰‹åŠ¨åˆ†é…åç»§ç»­",
                }
            )
            pause_event.set()
            resume_event.clear()
            await _autopilot_wait_resume(
                project_id, pause_event, resume_event, cancel_event
            )
