"""
Qwen3-TTS API Server
ä¸º HX-SayBook æä¾› REST API æ¥å£ï¼Œæ¡¥æ¥ Qwen2.5-Omni / Qwen3-TTS æ¨ç†å¼•æ“ã€‚
API æ¥å£ä¸ Index-TTS å®Œå…¨å…¼å®¹ï¼Œå¯æ— ç¼åˆ‡æ¢ã€‚

Qwen3-TTS ç‰¹ç‚¹ï¼š
  - åŸºäº Qwen2.5-Omni å¤šæ¨¡æ€æ¨¡å‹çš„ TTS èƒ½åŠ›
  - æ”¯æŒé›¶æ ·æœ¬è¯­éŸ³å…‹éš†ï¼ˆ3s å‚è€ƒéŸ³é¢‘ï¼‰
  - è¶…ä½å»¶è¿Ÿï¼ˆ97ms é¦–åŒ…ï¼‰
  - 10 ç§è¯­è¨€æ”¯æŒï¼ˆä¸­/è‹±/æ—¥/éŸ©/æ³•/å¾·/è¥¿/ä¿„/é˜¿/æ„ï¼‰
  - ä¸­æ–‡ WER 2.12%ï¼Œè¯´è¯äººç›¸ä¼¼åº¦ 0.89

æ¥å£åˆ—è¡¨ï¼ˆä¸ Index-TTS å®Œå…¨å…¼å®¹ï¼‰:
  GET  /              - æœåŠ¡ä¿¡æ¯ï¼ˆç”¨äºè¿æ¥æµ‹è¯•ï¼‰
  GET  /v1/models     - è·å–æ¨¡å‹ä¿¡æ¯
  POST /v2/synthesize - è¯­éŸ³åˆæˆ
  GET  /v1/check/audio - æ£€æŸ¥å‚è€ƒéŸ³é¢‘æ˜¯å¦å­˜åœ¨
  POST /v1/upload_audio - ä¸Šä¼ å‚è€ƒéŸ³é¢‘

å¯åŠ¨æ–¹å¼:
  python api_server_qwen3.py --host 0.0.0.0 --port 8000

ä¾èµ–:
  pip install transformers accelerate soundfile torch torchaudio
  pip install fastapi uvicorn[standard] python-multipart pydantic
"""

import argparse
import hashlib
import os
import sys
import threading
import time
import warnings

warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=UserWarning)

current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

import uvicorn
from fastapi import FastAPI, File, Form, UploadFile
from fastapi.responses import JSONResponse, Response
from pydantic import BaseModel
from typing import List, Optional

# ============================================================
# å‘½ä»¤è¡Œå‚æ•°
# ============================================================
parser = argparse.ArgumentParser(description="Qwen3-TTS API Server")
parser.add_argument("--host", type=str, default="0.0.0.0", help="ç›‘å¬åœ°å€")
parser.add_argument("--port", type=int, default=8000, help="ç›‘å¬ç«¯å£")
parser.add_argument(
    "--model_name", type=str, default="Qwen/Qwen2.5-Omni-7B",
    help="æ¨¡å‹åç§°æˆ–æœ¬åœ°è·¯å¾„"
)
parser.add_argument(
    "--device", type=str, default=None, help="æ¨ç†è®¾å¤‡ (cuda / cpu)"
)
parser.add_argument(
    "--torch_dtype", type=str, default="auto",
    help="æ¨¡å‹ç²¾åº¦ (auto / float16 / bfloat16)"
)
args, _ = parser.parse_known_args()

# ============================================================
# å…¨å±€å˜é‡
# ============================================================
PROMPTS_DIR = os.path.join(current_dir, "prompts")
os.makedirs(PROMPTS_DIR, exist_ok=True)

OUTPUTS_DIR = os.path.join(current_dir, "outputs", "api")
os.makedirs(OUTPUTS_DIR, exist_ok=True)

# Qwen2.5-Omni è¾“å‡ºé‡‡æ ·ç‡
OUTPUT_SAMPLE_RATE = 24000


# ============================================================
# Qwen3-TTS æ¨ç†ç®¡ç†å™¨
# ============================================================
class TTSModelManager:
    """Qwen3-TTS æ¨ç†ç®¡ç†å™¨

    ä½¿ç”¨ Qwen2.5-Omni æ¨¡å‹çš„ TTS èƒ½åŠ›è¿›è¡Œè¯­éŸ³åˆæˆã€‚
    æ”¯æŒé›¶æ ·æœ¬è¯­éŸ³å…‹éš†ï¼šé€šè¿‡å‚è€ƒéŸ³é¢‘å®ç°éŸ³è‰²è¿ç§»ã€‚
    """

    def __init__(self, model_name: str, device: str = None, torch_dtype: str = "auto"):
        self._model_name = model_name
        self._device = device or "cuda"
        self._torch_dtype = torch_dtype
        self._model = None
        self._processor = None
        self._infer_lock = threading.Lock()

    def load_model(self):
        """åŠ è½½ Qwen2.5-Omni æ¨¡å‹"""
        print(f"ğŸ“¦ åŠ è½½ Qwen3-TTS æ¨¡å‹: {self._model_name} ...")

        try:
            import torch

            # ç¡®å®šç²¾åº¦
            dtype_map = {
                "auto": "auto",
                "float16": torch.float16,
                "bfloat16": torch.bfloat16,
                "float32": torch.float32,
            }
            torch_dtype = dtype_map.get(self._torch_dtype, "auto")

            # å°è¯•å¯¼å…¥ Qwen2.5-Omni ä¸“ç”¨ç±»
            try:
                from transformers import Qwen2_5OmniModel, Qwen2_5OmniProcessor
                self._processor = Qwen2_5OmniProcessor.from_pretrained(self._model_name)
                self._model = Qwen2_5OmniModel.from_pretrained(
                    self._model_name,
                    torch_dtype=torch_dtype,
                    device_map=self._device,
                )
            except ImportError:
                # å›é€€åˆ°é€šç”¨ AutoModel
                from transformers import AutoModelForCausalLM, AutoProcessor
                self._processor = AutoProcessor.from_pretrained(self._model_name)
                self._model = AutoModelForCausalLM.from_pretrained(
                    self._model_name,
                    torch_dtype=torch_dtype,
                    device_map=self._device,
                    trust_remote_code=True,
                )

            print(f"âœ… Qwen3-TTS æ¨¡å‹åŠ è½½å®Œæˆ (device={self._device})")

        except Exception as e:
            import traceback
            print(f"âŒ Qwen3-TTS æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            traceback.print_exc()
            raise RuntimeError(f"Qwen3-TTS æ¨¡å‹åŠ è½½å¤±è´¥: {e}")

    def infer(
        self,
        prompt_wav: str,
        text: str,
        output_path: str,
        language: str = None,
        speed: float = 1.0,
    ) -> bool:
        """è°ƒç”¨ Qwen3-TTS è¿›è¡Œè¯­éŸ³åˆæˆ

        Args:
            prompt_wav: å‚è€ƒéŸ³é¢‘è·¯å¾„ï¼ˆç”¨äºéŸ³è‰²å…‹éš†ï¼‰
            text: è¦åˆæˆçš„æ–‡æœ¬
            output_path: è¾“å‡ºéŸ³é¢‘è·¯å¾„
            language: è¯­è¨€ä»£ç 
            speed: è¯­é€Ÿ (0.5~2.0)

        Returns:
            True if success, False otherwise
        """
        print(f"[æ¨ç†] text={text[:50]}... prompt={os.path.basename(prompt_wav)}")
        start_time = time.time()

        try:
            with self._infer_lock:
                import torch
                import soundfile as sf

                # æ„å»ºå¯¹è¯æ¶ˆæ¯ï¼ˆQwen2.5-Omni æ ¼å¼ï¼‰
                # é€šè¿‡ç³»ç»Ÿæç¤ºæŒ‡å®šä½¿ç”¨å‚è€ƒéŸ³é¢‘çš„å£°éŸ³
                messages = []

                # å¦‚æœæœ‰å‚è€ƒéŸ³é¢‘ï¼Œä½œä¸ºè¯­éŸ³å…‹éš†çš„å‚è€ƒ
                if prompt_wav and os.path.exists(prompt_wav):
                    messages.append({
                        "role": "system",
                        "content": [
                            {"type": "text", "text": "è¯·ä½¿ç”¨ä¸å‚è€ƒéŸ³é¢‘ç›¸åŒçš„å£°éŸ³é£æ ¼æœ—è¯»ä»¥ä¸‹æ–‡æœ¬ã€‚"},
                            {"type": "audio", "audio": prompt_wav},
                        ]
                    })
                else:
                    messages.append({
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªè¯­éŸ³åˆæˆåŠ©æ‰‹ï¼Œè¯·è‡ªç„¶åœ°æœ—è¯»æ–‡æœ¬ã€‚"
                    })

                # æ·»åŠ è¯­é€Ÿæç¤º
                speed_hint = ""
                if speed != 1.0:
                    if speed > 1.0:
                        speed_hint = f"ï¼ˆè¯·ä»¥è¾ƒå¿«çš„è¯­é€Ÿæœ—è¯»ï¼Œå¤§çº¦{speed}å€é€Ÿï¼‰"
                    else:
                        speed_hint = f"ï¼ˆè¯·ä»¥è¾ƒæ…¢çš„è¯­é€Ÿæœ—è¯»ï¼Œå¤§çº¦{speed}å€é€Ÿï¼‰"

                messages.append({
                    "role": "user",
                    "content": f"è¯·æœ—è¯»ï¼š{text}{speed_hint}"
                })

                # å¤„ç†è¾“å…¥
                inputs = self._processor(
                    messages=messages,
                    return_tensors="pt",
                ).to(self._model.device)

                # ç”Ÿæˆè¯­éŸ³
                with torch.no_grad():
                    # Qwen2.5-Omni åŒæ—¶ç”Ÿæˆæ–‡æœ¬å’ŒéŸ³é¢‘
                    try:
                        # å°è¯•ä½¿ç”¨ä¸“ç”¨çš„ TTS ç”Ÿæˆæ–¹æ³•
                        text_ids, audio_wav = self._model.generate(
                            **inputs,
                            use_audio_in_video=False,
                            return_audio=True,
                        )
                    except TypeError:
                        # å›é€€ï¼šé€šè¿‡é€šç”¨ generate æ–¹æ³•
                        outputs = self._model.generate(
                            **inputs,
                            max_new_tokens=4096,
                        )
                        # ä»è¾“å‡ºä¸­æå–éŸ³é¢‘
                        if hasattr(outputs, 'audio'):
                            audio_wav = outputs.audio
                        else:
                            print("[æ¨ç†] âš ï¸ æ¨¡å‹æœªè¿”å›éŸ³é¢‘æ•°æ®ï¼Œå°è¯•è§£ç ")
                            # è§£æè¾“å‡ºä¸­çš„éŸ³é¢‘ token
                            audio_wav = self._extract_audio_from_tokens(outputs)

                # ä¿å­˜éŸ³é¢‘
                if audio_wav is not None:
                    if hasattr(audio_wav, 'cpu'):
                        audio_wav = audio_wav.cpu()
                    if hasattr(audio_wav, 'numpy'):
                        audio_wav = audio_wav.numpy()
                    if audio_wav.ndim > 1:
                        audio_wav = audio_wav.squeeze()

                    sf.write(output_path, audio_wav, OUTPUT_SAMPLE_RATE)

            elapsed = time.time() - start_time

            # æ¸…ç†æ˜¾å­˜
            try:
                import torch
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
            except Exception:
                pass

            if os.path.isfile(output_path):
                file_size = os.path.getsize(output_path)
                print(f"[æ¨ç†] âœ… æˆåŠŸ ({elapsed:.2f}s, {file_size/1024:.1f}KB): {output_path}")
                return True
            else:
                print(f"[æ¨ç†] âŒ æ–‡ä»¶æœªç”Ÿæˆ: {output_path}")
                return False

        except Exception as e:
            import traceback
            elapsed = time.time() - start_time
            print(f"[æ¨ç†] âŒ å¼‚å¸¸ ({elapsed:.2f}s): {e}")
            traceback.print_exc()

            try:
                import torch
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
            except Exception:
                pass

            return False

    def _extract_audio_from_tokens(self, outputs):
        """ä»æ¨¡å‹è¾“å‡º token ä¸­æå–éŸ³é¢‘ï¼ˆå›é€€æ–¹æ³•ï¼‰"""
        # è¿™æ˜¯ä¸€ä¸ªå ä½å®ç°ï¼Œå…·ä½“å®ç°å–å†³äºæ¨¡å‹è¾“å‡ºæ ¼å¼
        print("[æ¨ç†] âš ï¸ ä½¿ç”¨å›é€€æ–¹æ³•æå–éŸ³é¢‘")
        return None

    @property
    def model_name(self):
        return self._model_name


# åˆ›å»ºæ¨¡å‹ç®¡ç†å™¨
tts_manager = TTSModelManager(
    model_name=args.model_name,
    device=args.device,
    torch_dtype=args.torch_dtype,
)

# ============================================================
# FastAPI åº”ç”¨
# ============================================================
app = FastAPI(title="Qwen3-TTS API", version="1.0.0")


@app.on_event("startup")
async def startup_event():
    """å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹"""
    print("=" * 50)
    print("  Qwen3-TTS API Server å¯åŠ¨ä¸­...")
    print(f"  æ¨¡å‹: {args.model_name}")
    print("=" * 50)
    tts_manager.load_model()
    print(f"\nğŸ Qwen3-TTS å°±ç»ª")


def _safe_filename(name: str) -> str:
    """å°†æ–‡ä»¶è·¯å¾„è½¬ä¸ºå®‰å…¨çš„æ–‡ä»¶å"""
    h = hashlib.md5(name.encode("utf-8")).hexdigest()[:16]
    ext = os.path.splitext(name)[1] or ".wav"
    return f"{h}{ext}"


# ============================================================
# GET / â€” æœåŠ¡ä¿¡æ¯ï¼ˆè¿æ¥æµ‹è¯•ï¼‰
# ============================================================
@app.get("/")
async def root():
    return {
        "name": "Qwen3-TTS API Server",
        "version": "1.0.0",
        "engine": "Qwen2.5-Omni TTS",
        "model": args.model_name,
        "sample_rate": OUTPUT_SAMPLE_RATE,
        "features": [
            "Zero-shot voice cloning (3s reference)",
            "Ultra-low latency (97ms first chunk)",
            "10 languages support",
            "Chinese WER 2.12%",
            "Speaker similarity 0.89",
        ],
        "endpoints": [
            "/v1/models",
            "/v2/synthesize",
            "/v1/check/audio",
            "/v1/upload_audio",
        ],
    }


# ============================================================
# GET /v1/models
# ============================================================
@app.get("/v1/models")
async def get_models():
    return {
        "models": [
            {
                "id": "qwen3-tts",
                "name": "Qwen3-TTS",
                "description": "Qwen2.5-Omni å¤šæ¨¡æ€æ¨¡å‹ TTS èƒ½åŠ›ï¼Œè¶…ä½å»¶è¿Ÿï¼Œ10 è¯­è¨€æ”¯æŒ",
                "model_name": tts_manager.model_name,
                "sample_rate": OUTPUT_SAMPLE_RATE,
                "languages": ["zh", "en", "ja", "ko", "fr", "de", "es", "ru", "ar", "it"],
            }
        ]
    }


# ============================================================
# POST /v2/synthesize â€” è¯­éŸ³åˆæˆï¼ˆå…¼å®¹ Index-TTS æ¥å£ï¼‰
# ============================================================
class SynthesizeRequest(BaseModel):
    text: str
    audio_path: str  # å‚è€ƒéŸ³é¢‘æ–‡ä»¶å
    emo_text: Optional[str] = None  # Qwen3 å¯é€šè¿‡æç¤ºè¯å®ç°æƒ…ç»ªï¼Œæ­¤å‚æ•°å…¼å®¹ä¿ç•™
    emo_vector: Optional[List[float]] = None  # å…¼å®¹ä¿ç•™ï¼ŒQwen3 ä¸ä½¿ç”¨
    language: Optional[str] = None  # è¯­è¨€
    speed: Optional[float] = None  # è¯­é€Ÿ 0.5~2.0


@app.post("/v2/synthesize")
async def synthesize(req: SynthesizeRequest):
    # æŸ¥æ‰¾å‚è€ƒéŸ³é¢‘
    safe_name = _safe_filename(req.audio_path)
    prompt_path = os.path.join(PROMPTS_DIR, safe_name)

    if not os.path.isfile(prompt_path):
        return JSONResponse(
            status_code=400,
            content={"error": f"å‚è€ƒéŸ³é¢‘ä¸å­˜åœ¨: {req.audio_path}ï¼Œè¯·å…ˆä¸Šä¼ "},
        )

    # ç”Ÿæˆè¾“å‡ºè·¯å¾„
    output_name = f"tts_{int(time.time() * 1000)}.wav"
    output_path = os.path.join(OUTPUTS_DIR, output_name)

    try:
        speed = 1.0
        if req.speed is not None:
            speed = max(0.5, min(2.0, req.speed))

        success = tts_manager.infer(
            prompt_wav=prompt_path,
            text=req.text,
            output_path=output_path,
            language=req.language,
            speed=speed,
        )

        if not success or not os.path.isfile(output_path):
            return JSONResponse(
                status_code=500,
                content={"error": "è¯­éŸ³åˆæˆå¤±è´¥ï¼Œè¯·æŸ¥çœ‹æœåŠ¡ç«¯æ—¥å¿—"},
            )

        with open(output_path, "rb") as f:
            audio_bytes = f.read()

        try:
            os.remove(output_path)
        except OSError:
            pass

        return Response(content=audio_bytes, media_type="audio/wav")

    except Exception as e:
        import traceback
        traceback.print_exc()
        return JSONResponse(
            status_code=500,
            content={"error": f"è¯­éŸ³åˆæˆå¼‚å¸¸: {str(e)}"},
        )


# ============================================================
# GET /v1/check/audio
# ============================================================
@app.get("/v1/check/audio")
async def check_audio(file_name: str):
    safe_name = _safe_filename(file_name)
    exists = os.path.isfile(os.path.join(PROMPTS_DIR, safe_name))
    return {"exists": exists, "file_name": file_name}


# ============================================================
# POST /v1/upload_audio
# ============================================================
@app.post("/v1/upload_audio")
async def upload_audio(
    audio: UploadFile = File(...),
    full_path: Optional[str] = Form(None),
):
    try:
        identifier = full_path or audio.filename or "unknown.wav"
        safe_name = _safe_filename(identifier)
        save_path = os.path.join(PROMPTS_DIR, safe_name)

        content = await audio.read()
        with open(save_path, "wb") as f:
            f.write(content)

        return {
            "code": 200,
            "msg": "ä¸Šä¼ æˆåŠŸ",
            "file_name": identifier,
            "saved_as": safe_name,
            "size": len(content),
        }
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"code": 500, "msg": f"ä¸Šä¼ å¤±è´¥: {str(e)}"},
        )


# ============================================================
# GET /v1/all_urls
# ============================================================
@app.get("/v1/all_urls")
async def get_all_urls():
    urls: list[str] = []

    env_urls = os.environ.get("TTS_ALL_URLS", "").strip()
    if env_urls:
        urls = [u.strip() for u in env_urls.split(",") if u.strip()]
    else:
        instance_count = int(os.environ.get("TTS_INSTANCE_COUNT", "0"))
        base_port = int(os.environ.get("TTS_BASE_PORT", str(args.port)))
        if instance_count > 1:
            host = os.environ.get("TTS_PUBLIC_HOST", "127.0.0.1")
            urls = [f"http://{host}:{base_port + i}" for i in range(instance_count)]
        else:
            host = os.environ.get("TTS_PUBLIC_HOST", "127.0.0.1")
            urls = [f"http://{host}:{args.port}"]

    return {
        "urls": urls,
        "count": len(urls),
        "copy_text": ", ".join(urls),
        "engine": "Qwen3-TTS",
    }


# ============================================================
# å¯åŠ¨æœåŠ¡
# ============================================================
if __name__ == "__main__":
    print(f"\nğŸš€ Qwen3-TTS API Server è¿è¡Œåœ¨ http://{args.host}:{args.port}")
    print(f"   æ¨¡å‹: {args.model_name}")
    print(f"   å‚è€ƒéŸ³é¢‘ç›®å½•: {PROMPTS_DIR}")
    print()
    uvicorn.run(app, host=args.host, port=args.port)
