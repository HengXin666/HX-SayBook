"""
Fish-Speech 1.5 API Serverï¼ˆæé€Ÿæ¨¡å¼ï¼‰
ä¸º HX-SayBook æä¾› REST API æ¥å£ï¼Œæ¡¥æ¥ Fish-Speech 1.5 æ¨ç†å¼•æ“ã€‚
API æ¥å£ä¸ Index-TTS å®Œå…¨å…¼å®¹ï¼Œå¯æ— ç¼åˆ‡æ¢ã€‚

è®¾è®¡ç›®æ ‡: å•è¯´è¯äºº + æé€Ÿæ¨ç† + ç®€å•éƒ¨ç½²
  - ä¸ä½¿ç”¨å¤šæƒ…ç»ªï¼ˆFish-Speech è‡ªèº«å¯ä»æ–‡æœ¬æ¨æ–­æƒ…ç»ªï¼‰
  - å•å‚è€ƒéŸ³é¢‘é¢„åŠ è½½ï¼Œé¿å…æ¯æ¬¡æ¨ç†é‡æ–°ç¼–ç 
  - RTF ~0.1ï¼Œå»¶è¿Ÿ <150msï¼Œæ˜¾å­˜ â‰¥4GB
  - ä½¿ç”¨ Fish-Speech è‡ªå¸¦ API server ä½œä¸ºåç«¯

ä¸¤ç§è¿è¡Œæ¨¡å¼:
  1. ç‹¬ç«‹æ¨¡å¼: å†…ç½® Fish-Speech æ¨ç†ï¼ˆéœ€å®‰è£… fish-speech åŒ…ï¼‰
  2. ä»£ç†æ¨¡å¼: è½¬å‘è¯·æ±‚åˆ° Fish-Speech è‡ªå¸¦ API server

æ¥å£åˆ—è¡¨ï¼ˆä¸ Index-TTS å®Œå…¨å…¼å®¹ï¼‰:
  GET  /              - æœåŠ¡ä¿¡æ¯ï¼ˆç”¨äºè¿æ¥æµ‹è¯•ï¼‰
  GET  /v1/models     - è·å–æ¨¡å‹ä¿¡æ¯
  POST /v2/synthesize - è¯­éŸ³åˆæˆ
  GET  /v1/check/audio - æ£€æŸ¥å‚è€ƒéŸ³é¢‘æ˜¯å¦å­˜åœ¨
  POST /v1/upload_audio - ä¸Šä¼ å‚è€ƒéŸ³é¢‘

å¯åŠ¨æ–¹å¼:
  # ä»£ç†æ¨¡å¼ï¼ˆæ¨èï¼Œå…ˆå¯åŠ¨ Fish-Speech è‡ªå¸¦ API serverï¼‰:
  python api_server_fish.py --mode proxy --fish_api http://localhost:8080

  # ç‹¬ç«‹æ¨¡å¼ï¼ˆéœ€å®‰è£… fish-speech åŒ…ï¼‰:
  python api_server_fish.py --mode standalone
"""

import argparse
import base64
import hashlib
import io
import os
import sys
import time
import warnings

warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=UserWarning)

current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

import uvicorn
from fastapi import FastAPI, File, Form, UploadFile
from fastapi.responses import JSONResponse, Response
from pydantic import BaseModel
from typing import List, Optional

# ============================================================
# å‘½ä»¤è¡Œå‚æ•°
# ============================================================
parser = argparse.ArgumentParser(description="Fish-Speech 1.5 API Server (æé€Ÿæ¨¡å¼)")
parser.add_argument("--host", type=str, default="0.0.0.0", help="ç›‘å¬åœ°å€")
parser.add_argument("--port", type=int, default=8000, help="ç›‘å¬ç«¯å£")
parser.add_argument(
    "--mode", type=str, default="proxy", choices=["proxy", "standalone"],
    help="è¿è¡Œæ¨¡å¼: proxy(ä»£ç†è½¬å‘) / standalone(ç‹¬ç«‹æ¨ç†)"
)
parser.add_argument(
    "--fish_api", type=str, default="http://localhost:8080",
    help="[ä»£ç†æ¨¡å¼] Fish-Speech API server åœ°å€"
)
parser.add_argument(
    "--model_path", type=str, default="checkpoints/fish-speech-1.5",
    help="[ç‹¬ç«‹æ¨¡å¼] Fish-Speech æ¨¡å‹è·¯å¾„"
)
parser.add_argument(
    "--device", type=str, default=None, help="æ¨ç†è®¾å¤‡ (cuda / cpu)"
)
parser.add_argument(
    "--compile", action="store_true", default=False,
    help="[ç‹¬ç«‹æ¨¡å¼] ä½¿ç”¨ torch.compile åŠ é€Ÿæ¨ç†"
)
args, _ = parser.parse_known_args()

# ============================================================
# å…¨å±€å˜é‡
# ============================================================
PROMPTS_DIR = os.path.join(current_dir, "prompts")
os.makedirs(PROMPTS_DIR, exist_ok=True)

OUTPUTS_DIR = os.path.join(current_dir, "outputs", "api")
os.makedirs(OUTPUTS_DIR, exist_ok=True)

# Fish-Speech è¾“å‡ºé‡‡æ ·ç‡
OUTPUT_SAMPLE_RATE = 44100


# ============================================================
# ä»£ç†æ¨¡å¼ï¼šå°†è¯·æ±‚è½¬å‘åˆ° Fish-Speech è‡ªå¸¦ API server
# ============================================================
class FishSpeechProxyEngine:
    """ä»£ç†æ¨¡å¼å¼•æ“ï¼šè½¬å‘è¯·æ±‚åˆ° Fish-Speech API server

    Fish-Speech è‡ªå¸¦ API server æä¾›ä»¥ä¸‹ç«¯ç‚¹:
      POST /v1/tts        - msgpack æ ¼å¼ï¼ˆé«˜æ•ˆï¼‰
      POST /audio/speech   - OpenAI å…¼å®¹æ ¼å¼ï¼ˆç®€å•ï¼‰

    æœ¬ä»£ç†ä½¿ç”¨ /audio/speech ç«¯ç‚¹ï¼Œå› ä¸ºå®ƒæ”¯æŒ form-data ä¸Šä¼ å‚è€ƒéŸ³é¢‘ã€‚
    """

    def __init__(self, fish_api_url: str):
        self._base_url = fish_api_url.rstrip("/")
        # ç¼“å­˜: reference_path -> reference_id
        self._ref_cache: dict[str, str] = {}

    def infer(
        self,
        prompt_wav: str,
        text: str,
        output_path: str,
        language: str = None,
    ) -> bool:
        """é€šè¿‡ä»£ç†è°ƒç”¨ Fish-Speech è¿›è¡Œè¯­éŸ³åˆæˆ"""
        import requests

        print(f"[ä»£ç†] text={text[:50]}... prompt={os.path.basename(prompt_wav)}")
        start_time = time.time()

        try:
            # è¯»å–å‚è€ƒéŸ³é¢‘
            with open(prompt_wav, "rb") as f:
                audio_data = f.read()

            # ä½¿ç”¨ /audio/speech ç«¯ç‚¹ï¼ˆOpenAI å…¼å®¹æ ¼å¼ï¼‰
            url = f"{self._base_url}/audio/speech"

            # form-data æ–¹å¼å‘é€
            files = {
                "reference_audio": (os.path.basename(prompt_wav), audio_data, "audio/wav"),
            }
            data = {
                "model": "fish-speech-1.5",
                "input": text,
                "response_format": "wav",
            }

            resp = requests.post(url, files=files, data=data, timeout=300)

            if resp.status_code != 200:
                # å›é€€: å°è¯• /v1/tts ç«¯ç‚¹
                print(f"[ä»£ç†] /audio/speech è¿”å› {resp.status_code}ï¼Œå°è¯• /v1/tts...")
                return self._infer_via_v1_tts(audio_data, text, output_path)

            # ä¿å­˜éŸ³é¢‘
            with open(output_path, "wb") as f:
                f.write(resp.content)

            elapsed = time.time() - start_time
            print(f"[ä»£ç†] âœ… æˆåŠŸ ({elapsed:.2f}s): {output_path}")
            return True

        except Exception as e:
            import traceback
            elapsed = time.time() - start_time
            print(f"[ä»£ç†] âŒ å¼‚å¸¸ ({elapsed:.2f}s): {e}")
            traceback.print_exc()
            return False

    def _infer_via_v1_tts(
        self,
        audio_data: bytes,
        text: str,
        output_path: str,
    ) -> bool:
        """å›é€€ï¼šé€šè¿‡ /v1/tts ç«¯ç‚¹å‘é€ï¼ˆmsgpack æ ¼å¼ï¼‰"""
        try:
            import requests

            # å°è¯•ä½¿ç”¨ ormsgpackï¼ˆFish-Speech æ¨èï¼‰
            try:
                import ormsgpack

                payload = {
                    "text": text,
                    "references": [
                        {
                            "audio": audio_data,
                            "text": "",  # Fish-Speech ä¼šè‡ªåŠ¨ ASR è¯†åˆ«
                        }
                    ],
                    "format": "wav",
                    "streaming": False,
                }

                url = f"{self._base_url}/v1/tts"
                resp = requests.post(
                    url,
                    data=ormsgpack.packb(payload),
                    headers={"Content-Type": "application/msgpack"},
                    timeout=300,
                )
            except ImportError:
                # æ²¡æœ‰ ormsgpackï¼Œç”¨ JSON + base64
                import json

                payload = {
                    "text": text,
                    "references": [
                        {
                            "audio": base64.b64encode(audio_data).decode(),
                            "text": "",
                        }
                    ],
                    "format": "wav",
                    "streaming": False,
                }

                url = f"{self._base_url}/v1/tts"
                resp = requests.post(
                    url,
                    json=payload,
                    timeout=300,
                )

            if resp.status_code == 200:
                with open(output_path, "wb") as f:
                    f.write(resp.content)
                return True
            else:
                print(f"[ä»£ç†] /v1/tts ä¹Ÿå¤±è´¥: {resp.status_code} {resp.text[:200]}")
                return False

        except Exception as e:
            print(f"[ä»£ç†] /v1/tts å¼‚å¸¸: {e}")
            return False


# ============================================================
# ç‹¬ç«‹æ¨¡å¼ï¼šç›´æ¥è°ƒç”¨ Fish-Speech æ¨ç†
# ============================================================
class FishSpeechStandaloneEngine:
    """ç‹¬ç«‹æ¨¡å¼å¼•æ“ï¼šç›´æ¥åŠ è½½ Fish-Speech æ¨¡å‹è¿›è¡Œæ¨ç†

    éœ€è¦å®‰è£… fish-speech åŒ…:
      pip install fish-speech
    æˆ–ä»æºç å®‰è£…:
      git clone https://github.com/fishaudio/fish-speech
      cd fish-speech && pip install -e .
    """

    def __init__(self, model_path: str, device: str = None, compile: bool = False):
        self._model_path = model_path
        self._device = device or "cuda"
        self._compile = compile
        self._model = None

    def load_model(self):
        """åŠ è½½ Fish-Speech æ¨¡å‹"""
        print(f"ğŸ“¦ åŠ è½½ Fish-Speech æ¨¡å‹: {self._model_path} ...")

        try:
            # Fish-Speech çš„æ¨ç† API
            from fish_speech.inference import TTSInference

            self._model = TTSInference(
                model_path=self._model_path,
                device=self._device,
                compile=self._compile,
            )
            print(f"âœ… Fish-Speech æ¨¡å‹åŠ è½½å®Œæˆ (device={self._device})")

        except ImportError:
            try:
                # å›é€€ï¼šå°è¯•å¦ä¸€ç§å¯¼å…¥æ–¹å¼
                from tools.llama.generate import load_model
                from tools.vqgan.inference import load_model as load_vqgan

                self._llama_model = load_model(
                    config_name="firefly_gan_vq",
                    checkpoint_path=os.path.join(self._model_path, "firefly-gan-vq-fsq-8x1024-21hz-generator.pth"),
                    device=self._device,
                )
                self._vqgan_model = load_vqgan(
                    config_name="firefly_gan_vq",
                    checkpoint_path=os.path.join(self._model_path, "firefly-gan-vq-fsq-8x1024-21hz-generator.pth"),
                    device=self._device,
                )
                print(f"âœ… Fish-Speech æ¨¡å‹åŠ è½½å®Œæˆ (å›é€€æ¨¡å¼, device={self._device})")

            except Exception as e2:
                raise RuntimeError(
                    f"Fish-Speech åŠ è½½å¤±è´¥: {e2}\n"
                    f"è¯·ç¡®ä¿å·²å®‰è£… fish-speech: pip install fish-speech\n"
                    f"æˆ–ä½¿ç”¨ä»£ç†æ¨¡å¼: --mode proxy"
                )

    def infer(
        self,
        prompt_wav: str,
        text: str,
        output_path: str,
        language: str = None,
    ) -> bool:
        """ç›´æ¥è°ƒç”¨ Fish-Speech è¿›è¡Œæ¨ç†"""
        print(f"[æ¨ç†] text={text[:50]}... prompt={os.path.basename(prompt_wav)}")
        start_time = time.time()

        try:
            import soundfile as sf

            if self._model is not None:
                # ä½¿ç”¨ TTSInference API
                audio = self._model.synthesize(
                    text=text,
                    reference_audio=prompt_wav,
                    reference_text="",  # è‡ªåŠ¨ ASR
                )

                if hasattr(audio, 'numpy'):
                    audio = audio.numpy()
                if audio.ndim > 1:
                    audio = audio.squeeze()

                sf.write(output_path, audio, OUTPUT_SAMPLE_RATE)
            else:
                print("[æ¨ç†] âŒ æ¨¡å‹æœªåŠ è½½")
                return False

            elapsed = time.time() - start_time

            # æ¸…ç†æ˜¾å­˜
            try:
                import torch
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
            except Exception:
                pass

            if os.path.isfile(output_path):
                file_size = os.path.getsize(output_path)
                print(f"[æ¨ç†] âœ… æˆåŠŸ ({elapsed:.2f}s, {file_size/1024:.1f}KB)")
                return True
            else:
                print(f"[æ¨ç†] âŒ æ–‡ä»¶æœªç”Ÿæˆ")
                return False

        except Exception as e:
            import traceback
            elapsed = time.time() - start_time
            print(f"[æ¨ç†] âŒ å¼‚å¸¸ ({elapsed:.2f}s): {e}")
            traceback.print_exc()
            return False


# ============================================================
# æ ¹æ®æ¨¡å¼é€‰æ‹©å¼•æ“
# ============================================================
if args.mode == "proxy":
    tts_engine = FishSpeechProxyEngine(fish_api_url=args.fish_api)
    engine_desc = f"ä»£ç†æ¨¡å¼ â†’ {args.fish_api}"
else:
    tts_engine = FishSpeechStandaloneEngine(
        model_path=args.model_path,
        device=args.device,
        compile=args.compile,
    )
    engine_desc = f"ç‹¬ç«‹æ¨¡å¼ ({args.model_path})"

# ============================================================
# FastAPI åº”ç”¨
# ============================================================
app = FastAPI(title="Fish-Speech 1.5 API (æé€Ÿæ¨¡å¼)", version="1.0.0")


@app.on_event("startup")
async def startup_event():
    """å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹ï¼ˆç‹¬ç«‹æ¨¡å¼ï¼‰"""
    print("=" * 50)
    print("  Fish-Speech 1.5 API Server (æé€Ÿæ¨¡å¼)")
    print(f"  æ¨¡å¼: {engine_desc}")
    print("  ç‰¹ç‚¹: å•è¯´è¯äºº / æé€Ÿæ¨ç† / æ˜¾å­˜ â‰¥4GB")
    print("=" * 50)

    if args.mode == "standalone":
        tts_engine.load_model()

    print(f"\nğŸ Fish-Speech æé€Ÿæ¨¡å¼å°±ç»ª")


def _safe_filename(name: str) -> str:
    """å°†æ–‡ä»¶è·¯å¾„è½¬ä¸ºå®‰å…¨çš„æ–‡ä»¶å"""
    h = hashlib.md5(name.encode("utf-8")).hexdigest()[:16]
    ext = os.path.splitext(name)[1] or ".wav"
    return f"{h}{ext}"


# ============================================================
# GET / â€” æœåŠ¡ä¿¡æ¯ï¼ˆè¿æ¥æµ‹è¯•ï¼‰
# ============================================================
@app.get("/")
async def root():
    return {
        "name": "Fish-Speech 1.5 API Server (æé€Ÿæ¨¡å¼)",
        "version": "1.0.0",
        "engine": "Fish-Speech 1.5",
        "mode": args.mode,
        "sample_rate": OUTPUT_SAMPLE_RATE,
        "features": [
            "Single speaker (fast mode)",
            "RTF ~0.1",
            "Latency <150ms",
            "VRAM â‰¥4GB",
            "Auto emotion from text",
        ],
        "endpoints": [
            "/v1/models",
            "/v2/synthesize",
            "/v1/check/audio",
            "/v1/upload_audio",
        ],
    }


# ============================================================
# GET /v1/models
# ============================================================
@app.get("/v1/models")
async def get_models():
    return {
        "models": [
            {
                "id": "fish-speech-1.5",
                "name": "Fish-Speech 1.5",
                "description": "Fish-Speech 1.5 æé€Ÿè¯­éŸ³åˆæˆ (DualAR, RTF 0.1, å•è¯´è¯äººæ¨¡å¼)",
                "mode": args.mode,
                "sample_rate": OUTPUT_SAMPLE_RATE,
            }
        ]
    }


# ============================================================
# POST /v2/synthesize â€” è¯­éŸ³åˆæˆï¼ˆå…¼å®¹ Index-TTS æ¥å£ï¼‰
# ============================================================
class SynthesizeRequest(BaseModel):
    text: str
    audio_path: str  # å‚è€ƒéŸ³é¢‘æ–‡ä»¶å
    emo_text: Optional[str] = None  # Fish-Speech è‡ªåŠ¨ä»æ–‡æœ¬æ¨æ–­æƒ…ç»ªï¼Œæ­¤å‚æ•°å¿½ç•¥
    emo_vector: Optional[List[float]] = None  # å…¼å®¹ä¿ç•™ï¼Œä¸ä½¿ç”¨
    language: Optional[str] = None  # è¯­è¨€
    speed: Optional[float] = None  # è¯­é€Ÿï¼ˆFish-Speech é€šè¿‡ text æ§åˆ¶ï¼Œæ­¤å‚æ•°ä¿ç•™å…¼å®¹ï¼‰


@app.post("/v2/synthesize")
async def synthesize(req: SynthesizeRequest):
    # æŸ¥æ‰¾å‚è€ƒéŸ³é¢‘
    safe_name = _safe_filename(req.audio_path)
    prompt_path = os.path.join(PROMPTS_DIR, safe_name)

    if not os.path.isfile(prompt_path):
        return JSONResponse(
            status_code=400,
            content={"error": f"å‚è€ƒéŸ³é¢‘ä¸å­˜åœ¨: {req.audio_path}ï¼Œè¯·å…ˆä¸Šä¼ "},
        )

    # ç”Ÿæˆè¾“å‡ºè·¯å¾„
    output_name = f"tts_{int(time.time() * 1000)}.wav"
    output_path = os.path.join(OUTPUTS_DIR, output_name)

    try:
        success = tts_engine.infer(
            prompt_wav=prompt_path,
            text=req.text,
            output_path=output_path,
            language=req.language,
        )

        if not success or not os.path.isfile(output_path):
            return JSONResponse(
                status_code=500,
                content={"error": "è¯­éŸ³åˆæˆå¤±è´¥ï¼Œè¯·æŸ¥çœ‹æœåŠ¡ç«¯æ—¥å¿—"},
            )

        with open(output_path, "rb") as f:
            audio_bytes = f.read()

        try:
            os.remove(output_path)
        except OSError:
            pass

        return Response(content=audio_bytes, media_type="audio/wav")

    except Exception as e:
        import traceback
        traceback.print_exc()
        return JSONResponse(
            status_code=500,
            content={"error": f"è¯­éŸ³åˆæˆå¼‚å¸¸: {str(e)}"},
        )


# ============================================================
# GET /v1/check/audio
# ============================================================
@app.get("/v1/check/audio")
async def check_audio(file_name: str):
    safe_name = _safe_filename(file_name)
    exists = os.path.isfile(os.path.join(PROMPTS_DIR, safe_name))
    return {"exists": exists, "file_name": file_name}


# ============================================================
# POST /v1/upload_audio
# ============================================================
@app.post("/v1/upload_audio")
async def upload_audio(
    audio: UploadFile = File(...),
    full_path: Optional[str] = Form(None),
):
    try:
        identifier = full_path or audio.filename or "unknown.wav"
        safe_name = _safe_filename(identifier)
        save_path = os.path.join(PROMPTS_DIR, safe_name)

        content = await audio.read()
        with open(save_path, "wb") as f:
            f.write(content)

        return {
            "code": 200,
            "msg": "ä¸Šä¼ æˆåŠŸ",
            "file_name": identifier,
            "saved_as": safe_name,
            "size": len(content),
        }
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"code": 500, "msg": f"ä¸Šä¼ å¤±è´¥: {str(e)}"},
        )


# ============================================================
# GET /v1/all_urls
# ============================================================
@app.get("/v1/all_urls")
async def get_all_urls():
    urls: list[str] = []

    env_urls = os.environ.get("TTS_ALL_URLS", "").strip()
    if env_urls:
        urls = [u.strip() for u in env_urls.split(",") if u.strip()]
    else:
        instance_count = int(os.environ.get("TTS_INSTANCE_COUNT", "0"))
        base_port = int(os.environ.get("TTS_BASE_PORT", str(args.port)))
        if instance_count > 1:
            host = os.environ.get("TTS_PUBLIC_HOST", "127.0.0.1")
            urls = [f"http://{host}:{base_port + i}" for i in range(instance_count)]
        else:
            host = os.environ.get("TTS_PUBLIC_HOST", "127.0.0.1")
            urls = [f"http://{host}:{args.port}"]

    return {
        "urls": urls,
        "count": len(urls),
        "copy_text": ", ".join(urls),
        "engine": "Fish-Speech 1.5 (æé€Ÿæ¨¡å¼)",
    }


# ============================================================
# å¯åŠ¨æœåŠ¡
# ============================================================
if __name__ == "__main__":
    print(f"\nğŸš€ Fish-Speech 1.5 API Server (æé€Ÿæ¨¡å¼) è¿è¡Œåœ¨ http://{args.host}:{args.port}")
    print(f"   æ¨¡å¼: {engine_desc}")
    print(f"   å‚è€ƒéŸ³é¢‘ç›®å½•: {PROMPTS_DIR}")
    print()
    uvicorn.run(app, host=args.host, port=args.port)
